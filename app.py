import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import quote
import re
from collections import Counter, defaultdict
import json
from datetime import datetime, timedelta
import io
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import base64
import os

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—É—á–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ---
EMAIL = st.secrets.get("EMAIL", "your.email@example.com") if hasattr(st, 'secrets') else "your.email@example.com"
MAX_WORKERS = 5
RETRIES = 3
DELAYS = [0.2, 0.5, 0.7, 1.0, 1.3, 1.5, 2.0]

# --- –ö–ª–∞—Å—Å—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
class AnalysisState:
    def __init__(self):
        self.crossref_cache = {}
        self.openalex_cache = {}
        self.unified_cache = {}
        self.citing_cache = defaultdict(list)
        self.institution_cache = {}
        self.journal_cache = {}
        self.analysis_results = None
        self.current_progress = 0
        self.progress_text = ""
        self.analysis_complete = False
        self.excel_buffer = None

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
def initialize_analysis_state():
    if 'analysis_state' not in st.session_state:
        st.session_state.analysis_state = AnalysisState()

def get_analysis_state():
    return st.session_state.analysis_state

# --- Rate Limiter ---
class RateLimiter:
    def __init__(self, calls_per_second=5):
        self.calls_per_second = calls_per_second
        self.timestamps = []
        self.lock = threading.Lock()
    
    def wait_if_needed(self):
        with self.lock:
            now = time.time()
            self.timestamps = [ts for ts in self.timestamps if now - ts < 1.0]
            
            if len(self.timestamps) >= self.calls_per_second:
                sleep_time = 1.0 - (now - self.timestamps[0])
                if sleep_time > 0:
                    time.sleep(sleep_time)
                self.timestamps = self.timestamps[1:]
            
            self.timestamps.append(now)

rate_limiter = RateLimiter(calls_per_second=8)

# --- –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ ---
class AdaptiveDelayer:
    def __init__(self):
        self.lock = threading.Lock()
        self.delay_index = 0

    def wait(self, success=True):
        with self.lock:
            if success:
                self.delay_index = 0
            else:
                self.delay_index = min(self.delay_index + 1, len(DELAYS) - 1)
            delay = DELAYS[self.delay_index]
            time.sleep(delay)
            return delay

delayer = AdaptiveDelayer()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
class JournalAnalyzerConfig:
    def __init__(self):
        self.email = EMAIL
        self.max_workers = MAX_WORKERS
        self.retries = RETRIES
        self.delays = DELAYS
        self.timeouts = {
            'crossref': 15,
            'openalex': 10,
            'batch': 30
        }
        self.batch_sizes = {
            'metadata': 10,
            'citations': 5
        }

config = JournalAnalyzerConfig()

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def update_progress(progress, text):
    state = get_analysis_state()
    state.current_progress = progress
    state.progress_text = text

# --- –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞ ---
def parse_period(period_str):
    years = set()
    parts = [p.strip() for p in period_str.replace(' ', '').split(',') if p.strip()]
    for part in parts:
        if '-' in part:
            try:
                s, e = map(int, part.split('-'))
                if 1900 <= s <= 2100 and 1900 <= e <= 2100 and s <= e:
                    years.update(range(s, e + 1))
                else:
                    st.warning(f"‚ö†Ô∏è –î–∏–∞–ø–∞–∑–æ–Ω –≤–Ω–µ 1900‚Äì2100 –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π: {part}")
            except ValueError:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞: {part}")
        else:
            try:
                y = int(part)
                if 1900 <= y <= 2100:
                    years.add(y)
                else:
                    st.warning(f"‚ö†Ô∏è –ì–æ–¥ –≤–Ω–µ 1900‚Äì2100: {y}")
            except ValueError:
                st.warning(f"‚ö†Ô∏è –ù–µ –≥–æ–¥: {part}")
    if not years:
        st.error("‚ùå –ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≥–æ–¥–æ–≤.")
        return []
    return sorted(years)

# --- –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
def validate_and_clean_data(items):
    validated = []
    skipped_count = 0
    
    for item in items:
        if not item.get('DOI'):
            skipped_count += 1
            continue
            
        doi = item['DOI'].lower().strip()
        if not doi.startswith('10.'):
            skipped_count += 1
            continue
            
        date_parts = item.get('created', {}).get('date-parts', [[]])[0]
        if not date_parts or date_parts[0] < 1900:
            skipped_count += 1
            continue
            
        item['DOI'] = doi
        validated.append(item)
    
    if skipped_count > 0:
        st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count} —Å—Ç–∞—Ç–µ–π –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏")
    return validated

# === 1. –ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ ===
def get_journal_name(issn):
    state = get_analysis_state()
    if issn in state.crossref_cache.get('journals', {}):
        return state.crossref_cache['journals'][issn]
    url = f"https://api.openalex.org/sources?filter=issn:{issn}"
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if data['meta']['count'] > 0:
                    name = data['results'][0]['display_name']
                    if 'journals' not in state.crossref_cache:
                        state.crossref_cache['journals'] = {}
                    state.crossref_cache['journals'][issn] = name
                    delayer.wait(success=True)
                    return name
        except:
            pass
        delayer.wait(success=False)
    return "–ñ—É—Ä–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"

# === 2. –ü–æ–ª—É—á–µ–Ω–∏–µ Crossref metadata ===
def get_crossref_metadata(doi, state):
    if doi in state.crossref_cache:
        return state.crossref_cache[doi]
    if not doi or doi == 'N/A':
        return None
    url = f"https://api.crossref.org/works/{quote(doi)}"
    headers = {'User-Agent': f"YourApp/1.0 (mailto:{EMAIL})"}
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, headers=headers, timeout=15)
            if resp.status_code == 200:
                data = resp.json()['message']
                state.crossref_cache[doi] = data
                delayer.wait(success=True)
                return data
        except:
            pass
        delayer.wait(success=False)
    return None

# === 3. –ü–æ–ª—É—á–µ–Ω–∏–µ OpenAlex metadata ===
def get_openalex_metadata(doi, state):
    if doi in state.openalex_cache:
        return state.openalex_cache[doi]
    if not doi or doi == 'N/A':
        return None
    normalized = doi if doi.startswith('http') else f"https://doi.org/{doi}"
    url = f"https://api.openalex.org/works/{quote(normalized)}"
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                state.openalex_cache[doi] = data
                delayer.wait(success=True)
                return data
        except:
            pass
        delayer.wait(success=False)
    return None

# === 4. –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ===
def get_unified_metadata(args):
    doi, state = args
    if doi in state.unified_cache:
        return state.unified_cache[doi]
    
    if not doi or doi == 'N/A':
        return {'crossref': None, 'openalex': None}
    
    cr_data = get_crossref_metadata(doi, state)
    oa_data = get_openalex_metadata(doi, state)
    
    result = {'crossref': cr_data, 'openalex': oa_data}
    state.unified_cache[doi] = result
    return result

# === 5. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö DOI –∏ –∏—Ö metadata ===
def get_citing_dois_and_metadata(args):
    analyzed_doi, state = args
    if analyzed_doi in state.citing_cache:
        return state.citing_cache[analyzed_doi]
    citing_list = []
    oa_data = get_openalex_metadata(analyzed_doi, state)
    if not oa_data or oa_data.get('cited_by_count', 0) == 0:
        state.citing_cache[analyzed_doi] = citing_list
        return citing_list
    work_id = oa_data['id'].split('/')[-1]
    url = f"https://api.openalex.org/works?filter=cites:{work_id}&per-page=100"
    cursor = "*"
    
    while cursor:
        success = False
        for _ in range(RETRIES):
            try:
                rate_limiter.wait_if_needed()
                resp = requests.get(f"{url}&cursor={cursor}", timeout=15)
                if resp.status_code == 200:
                    data = resp.json()
                    for w in data.get('results', []):
                        c_doi = w.get('doi')
                        if c_doi:
                            if c_doi not in state.crossref_cache:
                                get_crossref_metadata(c_doi, state)
                            if c_doi not in state.openalex_cache:
                                get_openalex_metadata(c_doi, state)
                            citing_list.append({
                                'doi': c_doi,
                                'pub_date': w.get('publication_date'),
                                'crossref': state.crossref_cache.get(c_doi),
                                'openalex': state.openalex_cache.get(c_doi)
                            })
                    cursor = data['meta'].get('next_cursor')
                    delayer.wait(success=True)
                    success = True
                    break
            except:
                pass
            delayer.wait(success=False)
        if not success:
            break
    state.citing_cache[analyzed_doi] = citing_list
    return citing_list

# === 6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π –∏ —Å—Ç—Ä–∞–Ω ===
def extract_affiliations_and_countries(openalex_data):
    affiliations = set()
    countries = set()
    authors_list = []
    
    if not openalex_data:
        return authors_list, list(affiliations), list(countries)
    
    if 'authorships' in openalex_data:
        for auth in openalex_data['authorships']:
            author_name = auth.get('author', {}).get('display_name', 'Unknown')
            authors_list.append(author_name)
            
            for inst in auth.get('institutions', []):
                inst_name = inst.get('display_name')
                country_code = inst.get('country_code')
                
                if inst_name:
                    affiliations.add(inst_name)
                if country_code:
                    countries.add(country_code.upper())
    
    return authors_list, list(affiliations), list(countries)

# === 7. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∂—É—Ä–Ω–∞–ª–µ ===
def extract_journal_info(metadata):
    journal_info = {
        'issn': [],
        'journal_name': '',
        'publisher': ''
    }
    
    if not metadata:
        return journal_info
    
    cr = metadata.get('crossref')
    if cr:
        journal_info['issn'] = cr.get('ISSN', [])
        journal_info['journal_name'] = cr.get('container-title', [''])[0] if cr.get('container-title') else ''
        journal_info['publisher'] = cr.get('publisher', '')
    
    oa = metadata.get('openalex')
    if oa:
        host_venue = oa.get('host_venue', {})
        if host_venue:
            if not journal_info['journal_name']:
                journal_info['journal_name'] = host_venue.get('display_name', '')
            if not journal_info['publisher']:
                journal_info['publisher'] = host_venue.get('publisher', '')
            if not journal_info['issn']:
                journal_info['issn'] = host_venue.get('issn', [])
    
    return journal_info

# === 8. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref ===
def fetch_articles_by_issn_period(issn, from_date, until_date):
    base_url = "https://api.crossref.org/works"
    items = []
    cursor = "*"
    params = {
        'filter': f'issn:{issn},from-pub-date:{from_date},until-pub-date:{until_date}',
        'rows': 1000,
        'cursor': cursor,
        'mailto': EMAIL
    }
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    progress_container = st.container()
    
    with progress_container:
        st.info("üì• –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö **Crossref** –∏ **OpenAlex**. –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Å–ª—É—á–∞–µ –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π –∏–ª–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è '–±—ã—Å—Ç—Ä–æ–π' —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞...")
    
    while cursor:
        params['cursor'] = cursor
        success = False
        for _ in range(RETRIES):
            try:
                rate_limiter.wait_if_needed()
                resp = requests.get(base_url, params=params, timeout=15)
                if resp.status_code == 200:
                    data = resp.json()
                    new_items = data['message']['items']
                    items.extend(new_items)
                    cursor = data['message'].get('next-cursor')
                    
                    status_text.text(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π...")
                    if cursor:
                        progress = min(len(items) / (len(items) + 100), 0.95)
                        progress_bar.progress(progress)
                    
                    delayer.wait(success=True)
                    success = True
                    break
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
            delayer.wait(success=False)
        if not success:
            break
        if not new_items:
            break
    
    progress_bar.progress(1.0)
    status_text.text(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π")
    time.sleep(0.5)
    progress_bar.empty()
    status_text.empty()
    progress_container.empty()
    
    return items

# === 9. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ DOI ===
def get_doi_prefix(doi):
    if not doi or doi == 'N/A':
        return ''
    return doi.split('/')[0] if '/' in doi else doi[:7]

# === 10. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º ===
def process_with_progress(items, func, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞", unit="—ç–ª–µ–º–µ–Ω—Ç–æ–≤"):
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(func, item): item for item in items}
        
        for i, future in enumerate(as_completed(futures)):
            try:
                results.append(future.result())
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –≤ {desc}: {e}")
                results.append(None)
            
            progress = (i + 1) / len(items)
            progress_bar.progress(progress)
            status_text.text(f"{desc}: {i + 1}/{len(items)}")
    
    progress_bar.empty()
    status_text.empty()
    return results

# === 11. –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏ ===
def analyze_overlaps(analyzed_metadata, citing_metadata, state):
    """–ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏"""
    
    overlap_details = []
    
    for analyzed in analyzed_metadata:
        if not analyzed or not analyzed.get('crossref'):
            continue
            
        analyzed_doi = analyzed['crossref'].get('DOI')
        if not analyzed_doi:
            continue
            
        # –ü–æ–ª—É—á–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã
        analyzed_authors, analyzed_affiliations, _ = extract_affiliations_and_countries(analyzed.get('openalex'))
        analyzed_authors_set = set(analyzed_authors)
        analyzed_affiliations_set = set(analyzed_affiliations)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã
        citings = get_citing_dois_and_metadata((analyzed_doi, state))
        
        for citing in citings:
            if not citing or not citing.get('openalex'):
                continue
                
            citing_doi = citing.get('doi')
            if not citing_doi:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã
            citing_authors, citing_affiliations, _ = extract_affiliations_and_countries(citing.get('openalex'))
            citing_authors_set = set(citing_authors)
            citing_affiliations_set = set(citing_affiliations)
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            common_authors = analyzed_authors_set.intersection(citing_authors_set)
            common_affiliations = analyzed_affiliations_set.intersection(citing_affiliations_set)
            
            if common_authors or common_affiliations:
                overlap_details.append({
                    'analyzed_doi': analyzed_doi,
                    'citing_doi': citing_doi,
                    'common_authors': list(common_authors),
                    'common_affiliations': list(common_affiliations),
                    'common_authors_count': len(common_authors),
                    'common_affiliations_count': len(common_affiliations)
                })
    
    return overlap_details

# === 12. –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π ===
def analyze_citation_accumulation(analyzed_metadata, state):
    accumulation_data = defaultdict(lambda: defaultdict(int))
    yearly_citations = defaultdict(int)
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if not analyzed_doi:
                continue
                
            pub_year = analyzed['crossref'].get('published', {}).get('date-parts', [[0]])[0][0]
            if not pub_year:
                continue
            
            citings = get_citing_dois_and_metadata((analyzed_doi, state))
            
            for citing in citings:
                if citing.get('openalex'):
                    cite_year = citing['openalex'].get('publication_year', 0)
                    if cite_year >= pub_year:
                        yearly_citations[cite_year] += 1
                        years_since_pub = cite_year - pub_year
                        if years_since_pub >= 0:
                            for year in range(years_since_pub + 1):
                                accumulation_data[pub_year][year] += 1
    
    accumulation_curves = {}
    for pub_year, yearly_counts in accumulation_data.items():
        sorted_years = sorted(yearly_counts.keys())
        cumulative_counts = []
        current_total = 0
        for year in sorted_years:
            current_total += yearly_counts[year]
            cumulative_counts.append({
                'years_since_publication': year,
                'cumulative_citations': current_total
            })
        accumulation_curves[pub_year] = cumulative_counts
    
    yearly_stats = []
    for year in sorted(yearly_citations.keys()):
        yearly_stats.append({
            'year': year,
            'citations_count': yearly_citations[year]
        })
    
    return {
        'accumulation_curves': dict(accumulation_curves),
        'yearly_citations': yearly_stats,
        'total_years_covered': len(yearly_citations)
    }

# === 13. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===
def extract_stats_from_metadata(metadata_list, is_analyzed=True, journal_prefix=''):
    total_refs = 0
    refs_with_doi = 0
    refs_without_doi = 0
    self_cites = 0
    ref_counts = []
    author_counts = []
    single_authors = 0
    multi_authors_gt10 = 0
    author_freq = Counter()
    pub_dates = []
    
    articles_with_10_citations = 0
    articles_with_20_citations = 0
    articles_with_30_citations = 0
    articles_with_50_citations = 0

    affiliations_freq = Counter()
    countries_freq = Counter()
    single_country_articles = 0
    multi_country_articles = 0
    no_country_articles = 0
    all_authors = []
    all_affiliations = []
    all_countries = []
    
    journal_freq = Counter()
    publisher_freq = Counter()

    for meta in metadata_list:
        if not meta:
            continue

        cr = meta.get('crossref')
        if cr:
            refs = cr.get('reference', [])
            total_refs += len(refs)
            for ref in refs:
                ref_doi = ref.get('DOI', '')
                if ref_doi:
                    refs_with_doi += 1
                    if get_doi_prefix(ref_doi) == journal_prefix:
                        self_cites += 1
                else:
                    refs_without_doi += 1
            ref_counts.append(len(refs))

            authors = cr.get('author', [])
            num_auth = len(authors)
            author_counts.append(num_auth)
            if num_auth == 1:
                single_authors += 1
            if num_auth > 10:
                multi_authors_gt10 += 1

            for auth in authors:
                family = auth.get('family', '').strip().title()
                given = auth.get('given', '').strip()
                initials = '.'.join([c + '.' for c in given if c.isupper()]) if given else ''
                if initials:
                    name = f"{family} {initials}"
                else:
                    name = family or 'Unknown'
                author_freq[name] += 1

            date_parts = cr.get('published', {}).get('date-parts', [[datetime.now().year]])[0]
            pub_date = datetime(date_parts[0], date_parts[1] if len(date_parts)>1 else 1, date_parts[2] if len(date_parts)>2 else 1)
            pub_dates.append(pub_date)
            
            journal_name = cr.get('container-title', [''])[0] if cr.get('container-title') else ''
            publisher = cr.get('publisher', '')
            if journal_name:
                journal_freq[journal_name] += 1
            if publisher:
                publisher_freq[publisher] += 1

        oa = meta.get('openalex')
        if oa:
            authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
            
            all_authors.extend(authors_list)
            all_affiliations.extend(affiliations_list)
            all_countries.extend(countries_list)
            
            for aff in affiliations_list:
                affiliations_freq[aff] += 1
            for country in countries_list:
                countries_freq[country] += 1
            
            unique_countries = set(countries_list)
            if len(unique_countries) == 0:
                no_country_articles += 1
            elif len(unique_countries) == 1:
                single_country_articles += 1
            elif len(unique_countries) > 1:
                multi_country_articles += 1
            
            host_venue = oa.get('host_venue', {})
            if host_venue:
                journal_name = host_venue.get('display_name', '')
                publisher = host_venue.get('publisher', '')
                if journal_name and journal_name not in journal_freq:
                    journal_freq[journal_name] += 1
                if publisher and publisher not in publisher_freq:
                    publisher_freq[publisher] += 1
            
            if is_analyzed:
                citation_count = oa.get('cited_by_count', 0)
                if citation_count >= 10:
                    articles_with_10_citations += 1
                if citation_count >= 20:
                    articles_with_20_citations += 1
                if citation_count >= 30:
                    articles_with_30_citations += 1
                if citation_count >= 50:
                    articles_with_50_citations += 1

    n_items = len(metadata_list)

    refs_with_doi_pct = (refs_with_doi / total_refs * 100) if total_refs > 0 else 0
    refs_without_doi_pct = (refs_without_doi / total_refs * 100) if total_refs > 0 else 0
    self_cites_pct = (self_cites / total_refs * 100) if total_refs > 0 else 0

    ref_min = min(ref_counts) if ref_counts else 0
    ref_max = max(ref_counts) if ref_counts else 0
    ref_mean = sum(ref_counts)/n_items if n_items > 0 else 0
    ref_median = sorted(ref_counts)[n_items//2] if n_items > 0 else 0

    auth_min = min(author_counts) if author_counts else 0
    auth_max = max(author_counts) if author_counts else 0
    auth_mean = sum(author_counts)/n_items if n_items > 0 else 0
    auth_median = sorted(author_counts)[n_items//2] if n_items > 0 else 0

    all_authors_sorted = author_freq.most_common()

    all_affiliations_sorted = affiliations_freq.most_common()
    all_countries_sorted = countries_freq.most_common()
    
    single_country_pct = (single_country_articles / n_items * 100) if n_items > 0 else 0
    multi_country_pct = (multi_country_articles / n_items * 100) if n_items > 0 else 0
    no_country_pct = (no_country_articles / n_items * 100) if n_items > 0 else 0

    all_journals_sorted = journal_freq.most_common()
    all_publishers_sorted = publisher_freq.most_common()

    return {
        'n_items': n_items,
        'total_refs': total_refs,
        'refs_with_doi': refs_with_doi, 'refs_with_doi_pct': refs_with_doi_pct,
        'refs_without_doi': refs_without_doi, 'refs_without_doi_pct': refs_without_doi_pct,
        'self_cites': self_cites, 'self_cites_pct': self_cites_pct,
        'ref_min': ref_min, 'ref_max': ref_max, 'ref_mean': ref_mean, 'ref_median': ref_median,
        'auth_min': auth_min, 'auth_max': auth_max, 'auth_mean': auth_mean, 'auth_median': auth_median,
        'single_authors': single_authors,
        'multi_authors_gt10': multi_authors_gt10,
        'all_authors': all_authors_sorted,
        'pub_dates': pub_dates,
        'articles_with_10_citations': articles_with_10_citations,
        'articles_with_20_citations': articles_with_20_citations,
        'articles_with_30_citations': articles_with_30_citations,
        'articles_with_50_citations': articles_with_50_citations,
        'all_affiliations': all_affiliations_sorted,
        'all_countries': all_countries_sorted,
        'all_authors_list': all_authors,
        'all_affiliations_list': all_affiliations,
        'all_countries_list': all_countries,
        'single_country_articles': single_country_articles, 
        'single_country_pct': single_country_pct,
        'multi_country_articles': multi_country_articles, 
        'multi_country_pct': multi_country_pct,
        'no_country_articles': no_country_articles,
        'no_country_pct': no_country_pct,
        'total_affiliations_count': len(all_affiliations),
        'unique_affiliations_count': len(set(all_affiliations)),
        'unique_countries_count': len(set(all_countries)),
        'all_journals': all_journals_sorted,
        'all_publishers': all_publishers_sorted,
        'unique_journals_count': len(journal_freq),
        'unique_publishers_count': len(publisher_freq)
    }

# === 14. –†–∞—Å—á–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===
def enhanced_stats_calculation(analyzed_metadata, citing_metadata, state):
    citation_network = defaultdict(list)
    citation_counts = []
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if analyzed_doi:
                analyzed_year = analyzed['crossref'].get('published', {}).get('date-parts', [[0]])[0][0]
                citings = get_citing_dois_and_metadata((analyzed_doi, state))
                citation_counts.append(len(citings))
                
                for citing in citings:
                    if citing.get('openalex'):
                        citing_year = citing['openalex'].get('publication_year', 0)
                        citation_network[analyzed_year].append(citing_year)
    
    citation_counts.sort(reverse=True)
    h_index = 0
    for i, count in enumerate(citation_counts):
        if count >= i + 1:
            h_index = i + 1
        else:
            break
    
    return {
        'h_index': h_index,
        'citation_network': dict(citation_network),
        'avg_citations_per_article': sum(citation_counts) / len(citation_counts) if citation_counts else 0,
        'max_citations': max(citation_counts) if citation_counts else 0,
        'min_citations': min(citation_counts) if citation_counts else 0,
        'total_citations': sum(citation_counts),
        'articles_with_citations': len([c for c in citation_counts if c > 0]),
        'articles_without_citations': len([c for c in citation_counts if c == 0])
    }

# === 15. –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
def calculate_citation_timing_stats(analyzed_metadata, state):
    all_days_to_first_citation = []
    citation_timing_stats = {}
    first_citation_details = []
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if not analyzed_doi:
                continue
                
            analyzed_date_parts = analyzed['crossref'].get('published', {}).get('date-parts', [[]])[0]
            if not analyzed_date_parts or len(analyzed_date_parts) < 1:
                continue
                
            analyzed_year = analyzed_date_parts[0]
            analyzed_month = analyzed_date_parts[1] if len(analyzed_date_parts) > 1 else 1
            analyzed_day = analyzed_date_parts[2] if len(analyzed_date_parts) > 2 else 1
            
            try:
                analyzed_date = datetime(analyzed_year, analyzed_month, analyzed_day)
            except:
                continue
            
            citings = get_citing_dois_and_metadata((analyzed_doi, state))
            citation_dates = []
            
            for citing in citings:
                if citing.get('pub_date'):
                    try:
                        cite_date = datetime.fromisoformat(citing['pub_date'].replace('Z', '+00:00'))
                        citation_dates.append((cite_date, citing.get('doi')))
                    except:
                        continue
            
            if citation_dates:
                first_citation_date, first_citing_doi = min(citation_dates, key=lambda x: x[0])
                days_to_first_citation = (first_citation_date - analyzed_date).days
                if days_to_first_citation >= 0:
                    all_days_to_first_citation.append(days_to_first_citation)
                    first_citation_details.append({
                        'analyzed_doi': analyzed_doi,
                        'citing_doi': first_citing_doi,
                        'analyzed_date': analyzed_date,
                        'first_citation_date': first_citation_date,
                        'days_to_first_citation': days_to_first_citation
                    })
    
    if all_days_to_first_citation:
        citation_timing_stats = {
            'min_days_to_first_citation': min(all_days_to_first_citation),
            'max_days_to_first_citation': max(all_days_to_first_citation),
            'mean_days_to_first_citation': np.mean(all_days_to_first_citation),
            'median_days_to_first_citation': np.median(all_days_to_first_citation),
            'articles_with_citation_timing_data': len(all_days_to_first_citation),
            'first_citation_details': first_citation_details
        }
    else:
        citation_timing_stats = {
            'min_days_to_first_citation': 0,
            'max_days_to_first_citation': 0,
            'mean_days_to_first_citation': 0,
            'median_days_to_first_citation': 0,
            'articles_with_citation_timing_data': 0,
            'first_citation_details': []
        }
    
    return citation_timing_stats

# === 16. –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
def calculate_citation_timing(analyzed_metadata, state):
    timing_stats = calculate_citation_timing_stats(analyzed_metadata, state)
    accumulation_stats = analyze_citation_accumulation(analyzed_metadata, state)
    
    return {
        'days_min': timing_stats['min_days_to_first_citation'],
        'days_max': timing_stats['max_days_to_first_citation'],
        'days_mean': timing_stats['mean_days_to_first_citation'],
        'days_median': timing_stats['median_days_to_first_citation'],
        'articles_with_timing_data': timing_stats['articles_with_citation_timing_data'],
        'first_citation_details': timing_stats['first_citation_details'],
        'accumulation_curves': accumulation_stats['accumulation_curves'],
        'yearly_citations': accumulation_stats['yearly_citations'],
        'total_years_covered': accumulation_stats['total_years_covered']
    }

# === –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò: –ë–´–°–¢–†–´–ï –ú–ï–¢–†–ò–ö–ò –ë–ï–ó API –ó–ê–ü–†–û–°–û–í ===

def calculate_reference_age_fast(analyzed_metadata, state):
    """–†–∞—Å—á–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞ —Å—Å—ã–ª–æ–∫ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API"""
    ref_ages = []
    current_year = datetime.now().year
    
    for meta in analyzed_metadata:
        cr = meta.get('crossref')
        if not cr: 
            continue
        
        pub_year = cr.get('published', {}).get('date-parts', [[0]])[0][0]
        if not pub_year: 
            continue
        
        for ref in cr.get('reference', []):
            # 1. –ü—Ä–æ–±—É–µ–º year –∏–∑ unstructured
            if 'year' in ref:
                try:
                    ref_year = int(ref['year'])
                    if 1900 <= ref_year <= current_year + 1:
                        ref_ages.append(current_year - ref_year)
                        continue
                except: 
                    pass
            
            # 2. –ü—Ä–æ–±—É–µ–º DOI –∏–∑ –∫—ç—à–∞ (—É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!)
            doi = ref.get('DOI')
            if doi and doi in state.crossref_cache:
                cached = state.crossref_cache[doi]
                date_parts = cached.get('published', {}).get('date-parts', [[0]])[0]
                if date_parts and date_parts[0]:
                    ref_year = date_parts[0]
                    ref_ages.append(current_year - ref_year)
    
    if not ref_ages: 
        return {
            'ref_median_age': None,
            'ref_mean_age': None,
            'ref_ages_25_75': [None, None],
            'total_refs_analyzed': 0
        }
    
    return {
        'ref_median_age': int(np.median(ref_ages)),
        'ref_mean_age': round(np.mean(ref_ages), 1),
        'ref_ages_25_75': [int(np.percentile(ref_ages, 25)), int(np.percentile(ref_ages, 75))],
        'total_refs_analyzed': len(ref_ages)
    }

def calculate_jscr_fast(citing_metadata, journal_issn):
    """Journal Self-Citation Rate - –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
    total = len(citing_metadata)
    if total == 0: 
        return {
            'JSCR': 0,
            'self_cites': 0,
            'total_cites': 0
        }
    
    self_cites = 0
    for c in citing_metadata:
        oa = c.get('openalex')
        if not oa: 
            continue
        issns = oa.get('host_venue', {}).get('issn', [])
        if journal_issn in issns:
            self_cites += 1
    
    return {
        'JSCR': round(self_cites / total * 100, 2),
        'self_cites': self_cites,
        'total_cites': total
    }

def calculate_cited_half_life_fast(analyzed_metadata, state):
    """Cited Half-Life - –º–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –¥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–æ–≤–∏–Ω—ã —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
    half_lives = []
    
    for meta in analyzed_metadata:
        if not meta or not meta.get('crossref'):
            continue
            
        doi = meta['crossref'].get('DOI')
        pub_year = meta['crossref'].get('published', {}).get('date-parts', [[0]])[0][0]
        if not doi or not pub_year: 
            continue
        
        citings = state.citing_cache.get(doi, [])
        if not citings: 
            continue
        
        yearly = defaultdict(int)
        for c in citings:
            y = c.get('openalex', {}).get('publication_year')
            if y: 
                yearly[y] += 1
        
        total = sum(yearly.values())
        if total == 0: 
            continue
            
        cumulative = 0
        target = total / 2
        for y in range(pub_year, pub_year + 50):
            cumulative += yearly[y]
            if cumulative >= target:
                half_lives.append(y - pub_year)
                break
    
    return {
        'cited_half_life_median': int(np.median(half_lives)) if half_lives else None,
        'cited_half_life_mean': round(np.mean(half_lives), 1) if half_lives else None,
        'articles_with_chl': len(half_lives)
    }

def calculate_fwci_fast(analyzed_metadata):
    """Field-Weighted Citation Impact - –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ –∏–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    total_cites = 0
    expected = 0.0
    
    for meta in analyzed_metadata:
        oa = meta.get('openalex')
        if not oa: 
            continue
            
        cites = oa.get('cited_by_count', 0)
        total_cites += cites
        
        concepts = oa.get('concepts', [])
        if not concepts: 
            continue
            
        main = max(concepts, key=lambda x: x.get('score', 0))
        works = max(main.get('works_count', 1), 1)
        field_cites = main.get('cited_by_count', 0)
        expected += (field_cites / works)
    
    fwci = total_cites / expected if expected > 0 else 0
    return {
        'FWCI': round(fwci, 2),
        'total_cites': total_cites,
        'expected_cites': round(expected, 2)
    }

def calculate_citation_velocity_fast(analyzed_metadata, state):
    """Citation Velocity - —Å—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –≤ –≥–æ–¥ –∑–∞ –ø–µ—Ä–≤—ã–µ 2 –≥–æ–¥–∞"""
    velocities = []
    current_year = datetime.now().year
    
    for meta in analyzed_metadata:
        cr = meta.get('crossref')
        if not cr: 
            continue
            
        pub_year = cr.get('published', {}).get('date-parts', [[0]])[0][0]
        if current_year - pub_year < 2: 
            continue
        
        citings = state.citing_cache.get(cr.get('DOI'), [])
        early = sum(1 for c in citings 
                   if c.get('openalex', {}).get('publication_year', 0) <= pub_year + 2)
        velocities.append(early / 2.0)
    
    return {
        'citation_velocity': round(np.mean(velocities), 2) if velocities else 0,
        'articles_with_velocity': len(velocities)
    }

def calculate_oa_impact_premium_fast(analyzed_metadata):
    """Open Access Impact Premium - —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è—Ö –º–µ–∂–¥—É OA –∏ –Ω–µ-OA"""
    oa_citations = []
    non_oa_citations = []
    
    for meta in analyzed_metadata:
        oa = meta.get('openalex')
        if not oa: 
            continue
            
        cites = oa.get('cited_by_count', 0)
        is_oa = oa.get('open_access', {}).get('is_oa', False)
        
        if is_oa:
            oa_citations.append(cites)
        else:
            non_oa_citations.append(cites)
    
    oa_avg = np.mean(oa_citations) if oa_citations else 0
    non_oa_avg = np.mean(non_oa_citations) if non_oa_citations else 0
    
    premium = ((oa_avg - non_oa_avg) / non_oa_avg * 100) if non_oa_avg > 0 else 0
    
    return {
        'OA_impact_premium': round(premium, 1),
        'OA_articles': len(oa_citations),
        'non_OA_articles': len(non_oa_citations),
        'OA_avg_citations': round(oa_avg, 1),
        'non_OA_avg_citations': round(non_oa_avg, 1)
    }

def calculate_elite_index_fast(analyzed_metadata):
    """Elite Index - –ø—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –≤ —Ç–æ–ø-10% –ø–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º"""
    if not analyzed_metadata:
        return {'elite_index': 0}
    
    citations = []
    for meta in analyzed_metadata:
        oa = meta.get('openalex')
        if oa:
            cites = oa.get('cited_by_count', 0)
            citations.append(cites)
    
    if not citations:
        return {'elite_index': 0}
    
    threshold = np.percentile(citations, 90)
    elite_count = sum(1 for c in citations if c >= threshold)
    
    return {
        'elite_index': round(elite_count / len(citations) * 100, 2),
        'elite_articles': elite_count,
        'total_articles': len(citations),
        'citation_threshold': int(threshold)
    }

def calculate_author_gini_fast(analyzed_metadata):
    """Author Gini Index - –∏–Ω–¥–µ–∫—Å –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π –ø–æ –∞–≤—Ç–æ—Ä–∞–º"""
    author_counts = Counter()
    
    for meta in analyzed_metadata:
        oa = meta.get('openalex')
        if oa and 'authorships' in oa:
            for auth in oa['authorships']:
                author_id = auth.get('author', {}).get('id')
                if author_id:
                    author_counts[author_id] += 1
    
    if len(author_counts) < 2:
        return {'author_gini': 0}
    
    # –†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–∞ –î–∂–∏–Ω–∏
    values = sorted(author_counts.values())
    n = len(values)
    cumulative = np.cumsum(values).astype(float)
    gini = (n + 1 - 2 * np.sum(cumulative) / cumulative[-1]) / n
    
    return {
        'author_gini': round(gini, 3),
        'total_authors': len(author_counts),
        'articles_per_author_avg': round(np.mean(values), 2),
        'articles_per_author_median': int(np.median(values))
    }

def calculate_dbi_fast(analyzed_metadata):
    """Diversity Balance Index - –∏–Ω–¥–µ–∫—Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–º–∞—Ç–∏–∫"""
    concept_freq = Counter()
    total_concepts = 0
    
    for meta in analyzed_metadata:
        oa = meta.get('openalex')
        if oa and 'concepts' in oa:
            concepts = oa['concepts']
            for concept in concepts[:3]:  # –ë–µ—Ä–µ–º —Ç–æ–ø-3 –∫–æ–Ω—Ü–µ–ø—Ç–∞
                concept_name = concept.get('display_name', '')
                if concept_name:
                    concept_freq[concept_name] += 1
                    total_concepts += 1
    
    if total_concepts == 0:
        return {'DBI': 0}
    
    # –ò–Ω–¥–µ–∫—Å –®–µ–Ω–Ω–æ–Ω–∞
    proportions = [count / total_concepts for count in concept_freq.values()]
    shannon = -sum(p * np.log(p) for p in proportions if p > 0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–º–∞–∫—Å–∏–º—É–º = log(n))
    max_shannon = np.log(len(concept_freq)) if concept_freq else 1
    dbi = shannon / max_shannon if max_shannon > 0 else 0
    
    return {
        'DBI': round(dbi, 3),
        'unique_concepts': len(concept_freq),
        'total_concept_mentions': total_concepts,
        'top_concepts': concept_freq.most_common(5)
    }

def calculate_all_fast_metrics(analyzed_metadata, citing_metadata, state, journal_issn):
    """–†–∞—Å—á–µ—Ç –≤—Å–µ—Ö –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫ –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥"""
    fast_metrics = {}
    
    # Reference Age
    fast_metrics.update(calculate_reference_age_fast(analyzed_metadata, state))
    
    # JSCR
    fast_metrics.update(calculate_jscr_fast(citing_metadata, journal_issn))
    
    # Cited Half-Life
    fast_metrics.update(calculate_cited_half_life_fast(analyzed_metadata, state))
    
    # FWCI
    fast_metrics.update(calculate_fwci_fast(analyzed_metadata))
    
    # Citation Velocity
    fast_metrics.update(calculate_citation_velocity_fast(analyzed_metadata, state))
    
    # OA Impact Premium
    fast_metrics.update(calculate_oa_impact_premium_fast(analyzed_metadata))
    
    # Elite Index
    fast_metrics.update(calculate_elite_index_fast(analyzed_metadata))
    
    # Author Gini
    fast_metrics.update(calculate_author_gini_fast(analyzed_metadata))
    
    # DBI
    fast_metrics.update(calculate_dbi_fast(analyzed_metadata))
    
    return fast_metrics

# === 17. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞ ===
def create_enhanced_excel_report(analyzed_data, citing_data, analyzed_stats, citing_stats, enhanced_stats, citation_timing, overlap_details, fast_metrics, excel_buffer):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    try:
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            # –õ–∏—Å—Ç 1: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ —Å—Ç–∞—Ç—å–∏ (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π)
            analyzed_list = []
            MAX_ROWS = 50000  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            
            for i, item in enumerate(analyzed_data):
                if i >= MAX_ROWS:
                    break
                if item and item.get('crossref'):
                    cr = item['crossref']
                    oa = item.get('openalex', {})
                    authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
                    journal_info = extract_journal_info(item)
                    
                    analyzed_list.append({
                        'DOI': cr.get('DOI', '')[:100],
                        '–ù–∞–∑–≤–∞–Ω–∏–µ': (cr.get('title', [''])[0] if cr.get('title') else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:200],
                        '–ê–≤—Ç–æ—Ä—ã_Crossref': '; '.join([f"{a.get('given', '')} {a.get('family', '')}" for a in cr.get('author', [])])[:300],
                        '–ê–≤—Ç–æ—Ä—ã_OpenAlex': '; '.join(authors_list)[:300],
                        '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(affiliations_list)[:500],
                        '–°—Ç—Ä–∞–Ω—ã': '; '.join(countries_list)[:100],
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': cr.get('published', {}).get('date-parts', [[0]])[0][0],
                        '–ñ—É—Ä–Ω–∞–ª': journal_info['journal_name'][:100],
                        '–ò–∑–¥–∞—Ç–µ–ª—å': journal_info['publisher'][:100],
                        'ISSN': '; '.join(journal_info['issn'])[:50],
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫': cr.get('reference-count', 0),
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Crossref': cr.get('is-referenced-by-count', 0),
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAlex': oa.get('cited_by_count', 0) if oa else 0,
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤': len(cr.get('author', [])),
                        '–¢–∏–ø —Ä–∞–±–æ—Ç—ã': cr.get('type', '')[:50]
                    })
            
            if analyzed_list:
                analyzed_df = pd.DataFrame(analyzed_list)
                analyzed_df.to_excel(writer, sheet_name='–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ_—Å—Ç–∞—Ç—å–∏', index=False)

            # –õ–∏—Å—Ç 2: –¶–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã (—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π)
            citing_list = []
            for i, item in enumerate(citing_data):
                if i >= MAX_ROWS:
                    break
                if item and item.get('crossref'):
                    cr = item['crossref']
                    oa = item.get('openalex', {})
                    authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
                    journal_info = extract_journal_info(item)
                    
                    citing_list.append({
                        'DOI': cr.get('DOI', '')[:100],
                        '–ù–∞–∑–≤–∞–Ω–∏–µ': (cr.get('title', [''])[0] if cr.get('title') else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:200],
                        '–ê–≤—Ç–æ—Ä—ã_Crossref': '; '.join([f"{a.get('given', '')} {a.get('family', '')}" for a in cr.get('author', [])])[:300],
                        '–ê–≤—Ç–æ—Ä—ã_OpenAlex': '; '.join(authors_list)[:300],
                        '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(affiliations_list)[:500],
                        '–°—Ç—Ä–∞–Ω—ã': '; '.join(countries_list)[:100],
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': cr.get('published', {}).get('date-parts', [[0]])[0][0],
                        '–ñ—É—Ä–Ω–∞–ª': journal_info['journal_name'][:100],
                        '–ò–∑–¥–∞—Ç–µ–ª—å': journal_info['publisher'][:100],
                        'ISSN': '; '.join(journal_info['issn'])[:50],
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫': cr.get('reference-count', 0),
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Crossref': cr.get('is-referenced-by-count', 0),
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAlex': oa.get('cited_by_count', 0) if oa else 0,
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤': len(cr.get('author', [])),
                        '–¢–∏–ø —Ä–∞–±–æ—Ç—ã': cr.get('type', '')[:50]
                    })
            
            if citing_list:
                citing_df = pd.DataFrame(citing_list)
                citing_df.to_excel(writer, sheet_name='–¶–∏—Ç–∏—Ä—É—é—â–∏–µ_—Ä–∞–±–æ—Ç—ã', index=False)

            # –õ–∏—Å—Ç 3: –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç
            overlap_list = []
            for overlap in overlap_details:
                overlap_list.append({
                    'DOI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã': overlap['analyzed_doi'][:100],
                    'DOI —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã': overlap['citing_doi'][:100],
                    '–°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∞–≤—Ç–æ—Ä—ã': '; '.join(overlap['common_authors'])[:300],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∞–≤—Ç–æ—Ä–æ–≤': overlap['common_authors_count'],
                    '–°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(overlap['common_affiliations'])[:500],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π': overlap['common_affiliations_count']
                })
            
            if overlap_list:
                overlap_df = pd.DataFrame(overlap_list)
                overlap_df.to_excel(writer, sheet_name='–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è_—Ä–∞–±–æ—Ç', index=False)

            # –õ–∏—Å—Ç 4: –í—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            first_citation_list = []
            for detail in citation_timing.get('first_citation_details', []):
                first_citation_list.append({
                    'DOI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã': detail['analyzed_doi'][:100],
                    'DOI –ø–µ—Ä–≤–æ–π —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã': detail['citing_doi'][:100],
                    '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': detail['analyzed_date'].strftime('%Y-%m-%d'),
                    '–î–∞—Ç–∞ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': detail['first_citation_date'].strftime('%Y-%m-%d'),
                    '–î–Ω–µ–π –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': detail['days_to_first_citation']
                })
            
            if first_citation_list:
                first_citation_df = pd.DataFrame(first_citation_list)
                first_citation_df.to_excel(writer, sheet_name='–ü–µ—Ä–≤—ã–µ_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', index=False)

            # –õ–∏—Å—Ç 5: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
            analyzed_stats_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': [
                    '–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π', 
                    '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫', 
                    '–°—Å—ã–ª–∫–∏ —Å DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ —Å DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ —Å DOI',
                    '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI',
                    '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                    '–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º',
                    '–°—Ç–∞—Ç—å–∏ —Å >10 –∞–≤—Ç–æ—Ä–∞–º–∏', 
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                    '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫',
                    '–ú–µ–¥–∏–∞–Ω–∞ —Å—Å—ã–ª–æ–∫', 
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤', 
                    '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                    '–ú–µ–¥–∏–∞–Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤', 
                    '–°—Ç–∞—Ç—å–∏ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã',
                    '–°—Ç–∞—Ç—å–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω',
                    '–°—Ç–∞—Ç—å–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö',
                    '–í—Å–µ–≥–æ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π', 
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π',
                    '–°—Ç–∞—Ç—å–∏ —Å ‚â•10 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                    '–°—Ç–∞—Ç—å–∏ —Å ‚â•20 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                    '–°—Ç–∞—Ç—å–∏ —Å ‚â•30 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                    '–°—Ç–∞—Ç—å–∏ —Å ‚â•50 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏'
                ],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    analyzed_stats['n_items'],
                    analyzed_stats['total_refs'],
                    '–°—Å—ã–ª–∫–∏ —Å DOI', analyzed_stats['refs_with_doi'], f"{analyzed_stats['refs_with_doi_pct']:.1f}%",
                    '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', analyzed_stats['refs_without_doi'], f"{analyzed_stats['refs_without_doi_pct']:.1f}%",
                    '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', analyzed_stats['self_cites'], f"{analyzed_stats['self_cites_pct']:.1f}%",
                    analyzed_stats['single_authors'],
                    analyzed_stats['multi_authors_gt10'],
                    analyzed_stats['ref_min'],
                    analyzed_stats['ref_max'],
                    f"{analyzed_stats['ref_mean']:.1f}",
                    analyzed_stats['ref_median'],
                    analyzed_stats['auth_min'],
                    analyzed_stats['auth_max'],
                    f"{analyzed_stats['auth_mean']:.1f}",
                    analyzed_stats['auth_median'],
                    analyzed_stats['single_country_articles'], f"{analyzed_stats['single_country_pct']:.1f}%",
                    analyzed_stats['multi_country_articles'], f"{analyzed_stats['multi_country_pct']:.1f}%",
                    analyzed_stats['no_country_articles'], f"{analyzed_stats['no_country_pct']:.1f}%",
                    analyzed_stats['total_affiliations_count'],
                    analyzed_stats['unique_affiliations_count'],
                    analyzed_stats['unique_countries_count'],
                    analyzed_stats['unique_journals_count'],
                    analyzed_stats['unique_publishers_count'],
                    analyzed_stats['articles_with_10_citations'],
                    analyzed_stats['articles_with_20_citations'],
                    analyzed_stats['articles_with_30_citations'],
                    analyzed_stats['articles_with_50_citations']
                ]
            }
            analyzed_stats_df = pd.DataFrame(analyzed_stats_data)
            analyzed_stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö', index=False)

            # –õ–∏—Å—Ç 6: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π
            citing_stats_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': [
                    '–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π', 
                    '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫', 
                    '–°—Å—ã–ª–∫–∏ —Å DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ —Å DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ —Å DOI',
                    '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI',
                    '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                    '–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º',
                    '–°—Ç–∞—Ç—å–∏ —Å >10 –∞–≤—Ç–æ—Ä–∞–º–∏', 
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                    '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫',
                    '–ú–µ–¥–∏–∞–Ω–∞ —Å—Å—ã–ª–æ–∫', 
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤', 
                    '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                    '–ú–µ–¥–∏–∞–Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤', 
                    '–°—Ç–∞—Ç—å–∏ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã',
                    '–°—Ç–∞—Ç—å–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω',
                    '–°—Ç–∞—Ç—å–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö',
                    '–í—Å–µ–≥–æ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π', 
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤',
                    '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π'
                ],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    citing_stats['n_items'],
                    citing_stats['total_refs'],
                    '–°—Å—ã–ª–∫–∏ —Å DOI', citing_stats['refs_with_doi'], f"{citing_stats['refs_with_doi_pct']:.1f}%",
                    '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', citing_stats['refs_without_doi'], f"{citing_stats['refs_without_doi_pct']:.1f}%",
                    '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', citing_stats['self_cites'], f"{citing_stats['self_cites_pct']:.1f}%",
                    citing_stats['single_authors'],
                    citing_stats['multi_authors_gt10'],
                    citing_stats['ref_min'],
                    citing_stats['ref_max'],
                    f"{citing_stats['ref_mean']:.1f}",
                    citing_stats['ref_median'],
                    citing_stats['auth_min'],
                    citing_stats['auth_max'],
                    f"{citing_stats['auth_mean']:.1f}",
                    citing_stats['auth_median'],
                    citing_stats['single_country_articles'], f"{citing_stats['single_country_pct']:.1f}%",
                    citing_stats['multi_country_articles'], f"{citing_stats['multi_country_pct']:.1f}%",
                    citing_stats['no_country_articles'], f"{citing_stats['no_country_pct']:.1f}%",
                    citing_stats['total_affiliations_count'],
                    citing_stats['unique_affiliations_count'],
                    citing_stats['unique_countries_count'],
                    citing_stats['unique_journals_count'],
                    citing_stats['unique_publishers_count']
                ]
            }
            citing_stats_df = pd.DataFrame(citing_stats_data)
            citing_stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞_—Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö', index=False)

            # –õ–∏—Å—Ç 7: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            enhanced_stats_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': [
                    'H-index', '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                    '–°—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é', '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–°—Ç–∞—Ç—å–∏ —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                    '–°—Ç–∞—Ç—å–∏ –±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'
                ],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    enhanced_stats['h_index'],
                    enhanced_stats['total_citations'],
                    f"{enhanced_stats['avg_citations_per_article']:.1f}",
                    enhanced_stats['max_citations'],
                    enhanced_stats['min_citations'],
                    enhanced_stats['articles_with_citations'],
                    enhanced_stats['articles_without_citations']
                ]
            }
            enhanced_stats_df = pd.DataFrame(enhanced_stats_data)
            enhanced_stats_df.to_excel(writer, sheet_name='–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)

            # –õ–∏—Å—Ç 8: –í—Ä–µ–º—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            citation_timing_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': [
                    '–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 
                    '–°—Ä–µ–¥–Ω–∏–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    '–ú–µ–¥–∏–∞–Ω–∞ –¥–Ω–µ–π –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 
                    '–°—Ç–∞—Ç—å–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    '–í—Å–µ–≥–æ –ª–µ—Ç –ø–æ–∫—Ä—ã—Ç–æ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è—Ö'
                ],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    citation_timing['days_min'],
                    citation_timing['days_max'],
                    f"{citation_timing['days_mean']:.1f}",
                    citation_timing['days_median'],
                    citation_timing['articles_with_timing_data'],
                    citation_timing['total_years_covered']
                ]
            }
            citation_timing_df = pd.DataFrame(citation_timing_data)
            citation_timing_df.to_excel(writer, sheet_name='–í—Ä–µ–º—è_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', index=False)

            # –õ–∏—Å—Ç 9: –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–æ–¥–∞–º
            yearly_citations_data = []
            for yearly_stat in citation_timing['yearly_citations']:
                yearly_citations_data.append({
                    '–ì–æ–¥': yearly_stat['year'],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π': yearly_stat['citations_count']
                })
            
            if yearly_citations_data:
                yearly_citations_df = pd.DataFrame(yearly_citations_data)
                yearly_citations_df.to_excel(writer, sheet_name='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è_–ø–æ_–≥–æ–¥–∞–º', index=False)

            # –õ–∏—Å—Ç 10: –ö—Ä–∏–≤—ã–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            accumulation_data = []
            for pub_year, curve_data in citation_timing['accumulation_curves'].items():
                for data_point in curve_data:
                    accumulation_data.append({
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_year,
                        '–õ–µ—Ç –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': data_point['years_since_publication'],
                        '–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': data_point['cumulative_citations']
                    })
            
            if accumulation_data:
                accumulation_df = pd.DataFrame(accumulation_data)
                accumulation_df.to_excel(writer, sheet_name='–ö—Ä–∏–≤—ã–µ_–Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', index=False)

            # –õ–∏—Å—Ç 11: –°–µ—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            citation_network_data = []
            for year, citing_years in enhanced_stats.get('citation_network', {}).items():
                year_counts = Counter(citing_years)
                for citing_year, count in year_counts.items():
                    citation_network_data.append({
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': year,
                        '–ì–æ–¥ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': citing_year,
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π': count
                    })
            
            if citation_network_data:
                citation_network_df = pd.DataFrame(citation_network_data)
                citation_network_df.to_excel(writer, sheet_name='–°–µ—Ç—å_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', index=False)

            # –õ–∏—Å—Ç 12: –í—Å–µ –∞–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
            if analyzed_stats['all_authors']:
                all_authors_data = {
                    '–ê–≤—Ç–æ—Ä': [author[0] for author in analyzed_stats['all_authors']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [author[1] for author in analyzed_stats['all_authors']]
                }
                all_authors_df = pd.DataFrame(all_authors_data)
                all_authors_df.to_excel(writer, sheet_name='–í—Å–µ_–∞–≤—Ç–æ—Ä—ã_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

            # –õ–∏—Å—Ç 13: –í—Å–µ –∞–≤—Ç–æ—Ä—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
            if citing_stats['all_authors']:
                all_citing_authors_data = {
                    '–ê–≤—Ç–æ—Ä': [author[0] for author in citing_stats['all_authors']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [author[1] for author in citing_stats['all_authors']]
                }
                all_citing_authors_df = pd.DataFrame(all_citing_authors_data)
                all_citing_authors_df.to_excel(writer, sheet_name='–í—Å–µ_–∞–≤—Ç–æ—Ä—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

            # –õ–∏—Å—Ç 14: –í—Å–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
            if analyzed_stats['all_affiliations']:
                all_affiliations_data = {
                    '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è': [aff[0] for aff in analyzed_stats['all_affiliations']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [aff[1] for aff in analyzed_stats['all_affiliations']]
                }
                all_affiliations_df = pd.DataFrame(all_affiliations_data)
                all_affiliations_df.to_excel(writer, sheet_name='–í—Å–µ_–∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

            # –õ–∏—Å—Ç 15: –í—Å–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
            if citing_stats['all_affiliations']:
                all_citing_affiliations_data = {
                    '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è': [aff[0] for aff in citing_stats['all_affiliations']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [aff[1] for aff in citing_stats['all_affiliations']]
                }
                all_citing_affiliations_df = pd.DataFrame(all_citing_affiliations_data)
                all_citing_affiliations_df.to_excel(writer, sheet_name='–í—Å–µ_–∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

            # –õ–∏—Å—Ç 16: –í—Å–µ —Å—Ç—Ä–∞–Ω—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
            if analyzed_stats['all_countries']:
                all_countries_data = {
                    '–°—Ç—Ä–∞–Ω–∞': [country[0] for country in analyzed_stats['all_countries']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [country[1] for country in analyzed_stats['all_countries']]
                }
                all_countries_df = pd.DataFrame(all_countries_data)
                all_countries_df.to_excel(writer, sheet_name='–í—Å–µ_—Å—Ç—Ä–∞–Ω—ã_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

            # –õ–∏—Å—Ç 17: –í—Å–µ —Å—Ç—Ä–∞–Ω—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
            if citing_stats['all_countries']:
                all_citing_countries_data = {
                    '–°—Ç—Ä–∞–Ω–∞': [country[0] for country in citing_stats['all_countries']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [country[1] for country in citing_stats['all_countries']]
                }
                all_citing_countries_df = pd.DataFrame(all_citing_countries_data)
                all_citing_countries_df.to_excel(writer, sheet_name='–í—Å–µ_—Å—Ç—Ä–∞–Ω—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

            # –õ–∏—Å—Ç 18: –í—Å–µ –∂—É—Ä–Ω–∞–ª—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
            if citing_stats['all_journals']:
                all_citing_journals_data = {
                    '–ñ—É—Ä–Ω–∞–ª': [journal[0] for journal in citing_stats['all_journals']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [journal[1] for journal in citing_stats['all_journals']]
                }
                all_citing_journals_df = pd.DataFrame(all_citing_journals_data)
                all_citing_journals_df.to_excel(writer, sheet_name='–í—Å–µ_–∂—É—Ä–Ω–∞–ª—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

            # –õ–∏—Å—Ç 19: –í—Å–µ –∏–∑–¥–∞—Ç–µ–ª–∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
            if citing_stats['all_publishers']:
                all_citing_publishers_data = {
                    '–ò–∑–¥–∞—Ç–µ–ª—å': [publisher[0] for publisher in citing_stats['all_publishers']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [publisher[1] for publisher in citing_stats['all_publishers']]
                }
                all_citing_publishers_df = pd.DataFrame(all_citing_publishers_data)
                all_citing_publishers_df.to_excel(writer, sheet_name='–í—Å–µ_–∏–∑–¥–∞—Ç–µ–ª–∏_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

            # –õ–∏—Å—Ç 20: –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–ù–û–í–´–ô)
            fast_metrics_data = {
                '–ú–µ—Ç—Ä–∏–∫–∞': [
                    'Reference Age (–º–µ–¥–∏–∞–Ω–∞)', 'Reference Age (—Å—Ä–µ–¥–Ω–µ–µ)',
                    'Reference Age (25-75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)', '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Å—ã–ª–æ–∫',
                    'Journal Self-Citation Rate (JSCR)', '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∂—É—Ä–Ω–∞–ª–∞',
                    '–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è JSCR',
                    'Cited Half-Life (–º–µ–¥–∏–∞–Ω–∞)', 'Cited Half-Life (—Å—Ä–µ–¥–Ω–µ–µ)',
                    '–°—Ç–∞—Ç—å–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è CHL',
                    'Field-Weighted Citation Impact (FWCI)', '–û–±—â–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    '–û–∂–∏–¥–∞–µ–º—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                    'Citation Velocity', '–°—Ç–∞—Ç—å–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è velocity',
                    'OA Impact Premium', 'OA —Å—Ç–∞—Ç–µ–π', '–ù–µ-OA —Å—Ç–∞—Ç–µ–π',
                    '–°—Ä–µ–¥–Ω–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OA', '–°—Ä–µ–¥–Ω–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ-OA',
                    'Elite Index', '–≠–ª–∏—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏', '–ü–æ—Ä–æ–≥ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                    'Author Gini Index', '–í—Å–µ–≥–æ –∞–≤—Ç–æ—Ä–æ–≤',
                    '–°—Ä–µ–¥–Ω–µ–µ —Å—Ç–∞—Ç–µ–π –Ω–∞ –∞–≤—Ç–æ—Ä–∞', '–ú–µ–¥–∏–∞–Ω–∞ —Å—Ç–∞—Ç–µ–π –Ω–∞ –∞–≤—Ç–æ—Ä–∞',
                    'Diversity Balance Index (DBI)', '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤',
                    '–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤'
                ],
                '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                    fast_metrics.get('ref_median_age', 'N/A'),
                    fast_metrics.get('ref_mean_age', 'N/A'),
                    f"{fast_metrics.get('ref_ages_25_75', ['N/A', 'N/A'])[0]}-{fast_metrics.get('ref_ages_25_75', ['N/A', 'N/A'])[1]}",
                    fast_metrics.get('total_refs_analyzed', 0),
                    f"{fast_metrics.get('JSCR', 0)}%",
                    fast_metrics.get('self_cites', 0),
                    fast_metrics.get('total_cites', 0),
                    fast_metrics.get('cited_half_life_median', 'N/A'),
                    fast_metrics.get('cited_half_life_mean', 'N/A'),
                    fast_metrics.get('articles_with_chl', 0),
                    fast_metrics.get('FWCI', 0),
                    fast_metrics.get('total_cites', 0),
                    fast_metrics.get('expected_cites', 0),
                    fast_metrics.get('citation_velocity', 0),
                    fast_metrics.get('articles_with_velocity', 0),
                    f"{fast_metrics.get('OA_impact_premium', 0)}%",
                    fast_metrics.get('OA_articles', 0),
                    fast_metrics.get('non_OA_articles', 0),
                    fast_metrics.get('OA_avg_citations', 0),
                    fast_metrics.get('non_OA_avg_citations', 0),
                    f"{fast_metrics.get('elite_index', 0)}%",
                    fast_metrics.get('elite_articles', 0),
                    fast_metrics.get('citation_threshold', 0),
                    fast_metrics.get('author_gini', 0),
                    fast_metrics.get('total_authors', 0),
                    fast_metrics.get('articles_per_author_avg', 0),
                    fast_metrics.get('articles_per_author_median', 0),
                    fast_metrics.get('DBI', 0),
                    fast_metrics.get('unique_concepts', 0),
                    fast_metrics.get('total_concept_mentions', 0)
                ]
            }
            fast_metrics_df = pd.DataFrame(fast_metrics_data)
            fast_metrics_df.to_excel(writer, sheet_name='–ë—ã—Å—Ç—Ä—ã–µ_–º–µ—Ç—Ä–∏–∫–∏', index=False)

            # –õ–∏—Å—Ç 21: –¢–æ–ø –∫–æ–Ω—Ü–µ–ø—Ç—ã (–ù–û–í–´–ô)
            if fast_metrics.get('top_concepts'):
                top_concepts_data = {
                    '–ö–æ–Ω—Ü–µ–ø—Ç': [concept[0] for concept in fast_metrics['top_concepts']],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [concept[1] for concept in fast_metrics['top_concepts']]
                }
                top_concepts_df = pd.DataFrame(top_concepts_data)
                top_concepts_df.to_excel(writer, sheet_name='–¢–æ–ø_–∫–æ–Ω—Ü–µ–ø—Ç—ã', index=False)

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ª–∏—Å—Ç
            if len(writer.sheets) == 0:
                error_df = pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞']})
                error_df.to_excel(writer, sheet_name='–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', index=False)

        excel_buffer.seek(0)
        return True

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel –æ—Ç—á–µ—Ç–∞: {str(e)}")
        # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –æ—à–∏–±–∫–æ–π
        try:
            excel_buffer.seek(0)
            excel_buffer.truncate(0)
            
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                error_df = pd.DataFrame({
                    '–û—à–∏–±–∫–∞': [f'–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: {str(e)}'],
                    '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': ['–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞']
                })
                error_df.to_excel(writer, sheet_name='–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', index=False)
            
            excel_buffer.seek(0)
            st.warning("‚ö†Ô∏è –°–æ–∑–¥–∞–Ω —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–∞–º—è—Ç–∏")
            return True
            
        except Exception as e2:
            st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {str(e2)}")
            return False

# === 18. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ===
def create_visualizations(analyzed_stats, citing_stats, enhanced_stats, citation_timing, overlap_details, fast_metrics):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞"""
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üìà –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏", 
        "üë• –ê–≤—Ç–æ—Ä—ã –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏", 
        "üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—è", 
        "üìä –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        "üîÄ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è",
        "‚è±Ô∏è –í—Ä–µ–º—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        "üöÄ –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏"  # –ù–û–í–ê–Ø –í–ö–õ–ê–î–ö–ê
    ])
    
    with tab1:
        st.subheader("üìà –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∂—É—Ä–Ω–∞–ª–∞")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("H-index", enhanced_stats['h_index'])
        with col2:
            st.metric("–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π", analyzed_stats['n_items'])
        with col3:
            st.metric("–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π", enhanced_stats['total_citations'])
        with col4:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π", f"{enhanced_stats['avg_citations_per_article']:.1f}")
        
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            st.metric("–°—Ç–∞—Ç—å–∏ —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏", enhanced_stats['articles_with_citations'])
        with col6:
            st.metric("–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{analyzed_stats['self_cites_pct']:.1f}%")
        with col7:
            st.metric("–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏", f"{analyzed_stats['multi_country_pct']:.1f}%")
        with col8:
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π", analyzed_stats['unique_affiliations_count'])
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ –≥–æ–¥–∞–º
        if citation_timing['yearly_citations']:
            years = [item['year'] for item in citation_timing['yearly_citations']]
            citations = [item['citations_count'] for item in citation_timing['yearly_citations']]
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=years, 
                y=citations, 
                name='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                marker_color='lightblue'
            ))
            fig.update_layout(
                title='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–æ–¥–∞–º',
                xaxis_title='–ì–æ–¥',
                yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("üë• –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä–æ–≤ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –¢–æ–ø –∞–≤—Ç–æ—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
            if analyzed_stats['all_authors']:
                top_authors = analyzed_stats['all_authors'][:15]
                authors_df = pd.DataFrame(top_authors, columns=['–ê–≤—Ç–æ—Ä', '–°—Ç–∞—Ç–µ–π'])
                fig = px.bar(
                    authors_df, 
                    x='–°—Ç–∞—Ç–µ–π', 
                    y='–ê–≤—Ç–æ—Ä', 
                    orientation='h',
                    title='–¢–æ–ø-15 –∞–≤—Ç–æ—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ—Ä–æ–≤
            author_counts_data = {
                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': ['1 –∞–≤—Ç–æ—Ä', '2-5 –∞–≤—Ç–æ—Ä–æ–≤', '6-10 –∞–≤—Ç–æ—Ä–æ–≤', '>10 –∞–≤—Ç–æ—Ä–æ–≤'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats['single_authors'],
                    analyzed_stats['n_items'] - analyzed_stats['single_authors'] - analyzed_stats['multi_authors_gt10'],
                    analyzed_stats['multi_authors_gt10'],
                    0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é
                ]
            }
            fig = px.pie(
                author_counts_data, 
                values='–°—Ç–∞—Ç—å–∏', 
                names='–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–≤—Ç–æ—Ä–æ–≤'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # –¢–æ–ø –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π
        if analyzed_stats['all_affiliations']:
            top_affiliations = analyzed_stats['all_affiliations'][:10]
            aff_df = pd.DataFrame(top_affiliations, columns=['–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è', '–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'])
            fig = px.bar(
                aff_df, 
                x='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π', 
                y='–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è', 
                orientation='h',
                title='–¢–æ–ø-10 –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π',
                color='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º
            if analyzed_stats['all_countries']:
                countries_df = pd.DataFrame(analyzed_stats['all_countries'], columns=['–°—Ç—Ä–∞–Ω–∞', '–°—Ç–∞—Ç–µ–π'])
                fig = px.pie(
                    countries_df, 
                    values='–°—Ç–∞—Ç–µ–π', 
                    names='–°—Ç—Ä–∞–Ω–∞',
                    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –ø–æ —Å—Ç—Ä–∞–Ω–∞–º'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è
            collaboration_data = {
                '–¢–∏–ø': ['–û–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∞', '–ù–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats['single_country_articles'],
                    analyzed_stats['multi_country_articles'],
                    analyzed_stats['no_country_articles']
                ]
            }
            fig = px.bar(
                collaboration_data, 
                x='–¢–∏–ø', 
                y='–°—Ç–∞—Ç—å–∏',
                title='–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è',
                color='–¢–∏–ø'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –ø–æ—Ä–æ–≥–∞–º
            citation_thresholds = {
                '–ü–æ—Ä–æ–≥': ['‚â•10', '‚â•20', '‚â•30', '‚â•50'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats['articles_with_10_citations'],
                    analyzed_stats['articles_with_20_citations'],
                    analyzed_stats['articles_with_30_citations'],
                    analyzed_stats['articles_with_50_citations']
                ]
            }
            fig = px.bar(
                citation_thresholds, 
                x='–ü–æ—Ä–æ–≥', 
                y='–°—Ç–∞—Ç—å–∏',
                title='–°—Ç–∞—Ç—å–∏ –ø–æ –ø–æ—Ä–æ–≥–∞–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                color='–ü–æ—Ä–æ–≥'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –°—Ç–∞—Ç—å–∏ —Å/–±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            citation_status = {
                '–°—Ç–∞—Ç—É—Å': ['–° —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏', '–ë–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'],
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [
                    enhanced_stats['articles_with_citations'],
                    enhanced_stats['articles_without_citations']
                ]
            }
            fig = px.pie(
                citation_status, 
                values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 
                names='–°—Ç–∞—Ç—É—Å',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –ø–æ –Ω–∞–ª–∏—á–∏—é —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab5:
        st.subheader("üîÄ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏")
        
        if overlap_details:
            # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è–º
            total_overlaps = len(overlap_details)
            articles_with_overlaps = len(set([o['analyzed_doi'] for o in overlap_details]))
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π", total_overlaps)
            with col2:
                st.metric("–°—Ç–∞—Ç–µ–π —Å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è–º–∏", articles_with_overlaps)
            with col3:
                avg_overlaps = total_overlaps / articles_with_overlaps if articles_with_overlaps > 0 else 0
                st.metric("–°—Ä–µ–¥–Ω–µ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é", f"{avg_overlaps:.1f}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
            overlap_counts = [o['common_authors_count'] + o['common_affiliations_count'] for o in overlap_details]
            if overlap_counts:
                fig = px.histogram(
                    x=overlap_counts,
                    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É',
                    labels={'x': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π', 'y': '–ß–∞—Å—Ç–æ—Ç–∞'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª—è–º–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
            st.subheader("–î–µ—Ç–∞–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π")
            overlap_df = pd.DataFrame(overlap_details)
            st.dataframe(overlap_df[['analyzed_doi', 'citing_doi', 'common_authors_count', 'common_affiliations_count']])
        else:
            st.info("‚ùå –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    with tab6:
        st.subheader("‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–ú–∏–Ω. –¥–Ω–µ–π –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", citation_timing['days_min'])
        with col2:
            st.metric("–ú–∞–∫—Å. –¥–Ω–µ–π –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", citation_timing['days_max'])
        with col3:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –¥–Ω–µ–π", f"{citation_timing['days_mean']:.1f}")
        with col4:
            st.metric("–ú–µ–¥–∏–∞–Ω–∞ –¥–Ω–µ–π", citation_timing['days_median'])
        
        # –î–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        if citation_timing['first_citation_details']:
            st.subheader("–î–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
            first_citation_df = pd.DataFrame(citation_timing['first_citation_details'])
            st.dataframe(first_citation_df)
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            days_data = [d['days_to_first_citation'] for d in citation_timing['first_citation_details']]
            fig = px.histogram(
                x=days_data,
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–Ω–∏)',
                labels={'x': '–î–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π'}
            )
            st.plotly_chart(fig, use_container_width=True)

    with tab7:
        st.subheader("üöÄ –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –±–µ–∑ API –∑–∞–ø—Ä–æ—Å–æ–≤)")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –±—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Reference Age", f"{fast_metrics.get('ref_median_age', 'N/A')} –ª–µ—Ç")
        with col2:
            st.metric("JSCR", f"{fast_metrics.get('JSCR', 0)}%")
        with col3:
            st.metric("Cited Half-Life", f"{fast_metrics.get('cited_half_life_median', 'N/A')} –ª–µ—Ç")
        with col4:
            st.metric("FWCI", fast_metrics.get('FWCI', 0))
        
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            st.metric("Citation Velocity", fast_metrics.get('citation_velocity', 0))
        with col6:
            st.metric("OA Impact Premium", f"{fast_metrics.get('OA_impact_premium', 0)}%")
        with col7:
            st.metric("Elite Index", f"{fast_metrics.get('elite_index', 0)}%")
        with col8:
            st.metric("Author Gini", fast_metrics.get('author_gini', 0))
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö
        st.subheader("üìä –î–µ—Ç–∞–ª–∏ –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Reference Age —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            if fast_metrics.get('ref_median_age') is not None:
                st.write("**Reference Age:**")
                st.write(f"- –ú–µ–¥–∏–∞–Ω–∞: {fast_metrics['ref_median_age']} –ª–µ—Ç")
                st.write(f"- –°—Ä–µ–¥–Ω–µ–µ: {fast_metrics['ref_mean_age']} –ª–µ—Ç")
                st.write(f"- 25-75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å: {fast_metrics['ref_ages_25_75'][0]}-{fast_metrics['ref_ages_25_75'][1]} –ª–µ—Ç")
                st.write(f"- –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Å—ã–ª–æ–∫: {fast_metrics['total_refs_analyzed']}")
        
        with col2:
            # JSCR –¥–µ—Ç–∞–ª–∏
            st.write("**Journal Self-Citation Rate:**")
            st.write(f"- –°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {fast_metrics.get('self_cites', 0)}")
            st.write(f"- –í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π: {fast_metrics.get('total_cites', 0)}")
            st.write(f"- –ü—Ä–æ—Ü–µ–Ω—Ç: {fast_metrics.get('JSCR', 0)}%")
        
        col3, col4 = st.columns(2)
        
        with col3:
            # Citation Velocity
            st.write("**Citation Velocity:**")
            st.write(f"- –°—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π/–≥–æ–¥: {fast_metrics.get('citation_velocity', 0)}")
            st.write(f"- –°—Ç–∞—Ç—å–∏ —Å –¥–∞–Ω–Ω—ã–º–∏: {fast_metrics.get('articles_with_velocity', 0)}")
        
        with col4:
            # OA Impact Premium
            st.write("**OA Impact Premium:**")
            st.write(f"- –ü—Ä–µ–º–∏—è: {fast_metrics.get('OA_impact_premium', 0)}%")
            st.write(f"- OA —Å—Ç–∞—Ç–µ–π: {fast_metrics.get('OA_articles', 0)}")
            st.write(f"- –ù–µ-OA —Å—Ç–∞—Ç–µ–π: {fast_metrics.get('non_OA_articles', 0)}")
        
        # –¢–æ–ø –∫–æ–Ω—Ü–µ–ø—Ç—ã
        if fast_metrics.get('top_concepts'):
            st.subheader("üè∑Ô∏è –¢–æ–ø-5 —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
            concepts_df = pd.DataFrame(fast_metrics['top_concepts'], columns=['–ö–æ–Ω—Ü–µ–ø—Ç', '–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'])
            fig = px.bar(
                concepts_df,
                x='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π',
                y='–ö–æ–Ω—Ü–µ–ø—Ç',
                orientation='h',
                title='–¢–æ–ø —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤',
                color='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'
            )
            st.plotly_chart(fig, use_container_width=True)

# === 19. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ ===
def analyze_journal(issn, period_str):
    global delayer
    delayer = AdaptiveDelayer()
    
    state = get_analysis_state()
    state.analysis_complete = False
    
    # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    overall_progress = st.progress(0)
    overall_status = st.empty()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞
    overall_status.text("üìÖ –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞...")
    years = parse_period(period_str)
    if not years:
        return
    from_date = f"{min(years)}-01-01"
    until_date = f"{max(years)}-12-31"
    overall_progress.progress(0.1)
    
    # –ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞
    overall_status.text("üìñ –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∂—É—Ä–Ω–∞–ª–∞...")
    journal_name = get_journal_name(issn)
    st.success(f"üìñ –ñ—É—Ä–Ω–∞–ª: **{journal_name}** (ISSN: {issn})")
    overall_progress.progress(0.2)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π
    overall_status.text("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref...")
    items = fetch_articles_by_issn_period(issn, from_date, until_date)
    if not items:
        st.error("‚ùå –°—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    n_analyzed = len(items)
    st.success(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π: **{n_analyzed}**")
    overall_progress.progress(0.3)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    overall_status.text("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    validated_items = validate_and_clean_data(items)
    journal_prefix = get_doi_prefix(validated_items[0].get('DOI', '')) if validated_items else ''
    overall_progress.progress(0.4)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
    overall_status.text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π...")
    
    analyzed_metadata = []
    dois = [item.get('DOI') for item in validated_items if item.get('DOI')]
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    meta_progress = st.progress(0)
    meta_status = st.empty()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤
    args_list = [(doi, state) for doi in dois]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(get_unified_metadata, args): args for args in args_list}
        
        for i, future in enumerate(as_completed(futures)):
            args = futures[future]
            doi = args[0]
            try:
                result = future.result()
                analyzed_metadata.append({
                    'doi': doi,
                    'crossref': result['crossref'],
                    'openalex': result['openalex']
                })
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOI {doi}: {e}")
            
            progress = (i + 1) / len(dois)
            meta_progress.progress(progress)
            meta_status.text(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {i + 1}/{len(dois)}")
    
    meta_progress.empty()
    meta_status.empty()
    overall_progress.progress(0.6)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç
    overall_status.text("üîó –°–±–æ—Ä —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç...")
    
    all_citing_metadata = []
    analyzed_dois = [am['doi'] for am in analyzed_metadata if am.get('doi')]
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è —Å–±–æ—Ä–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
    citing_progress = st.progress(0)
    citing_status = st.empty()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤
    citing_args_list = [(doi, state) for doi in analyzed_dois]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(get_citing_dois_and_metadata, args): args for args in citing_args_list}
        
        for i, future in enumerate(as_completed(futures)):
            args = futures[future]
            doi = args[0]
            try:
                citings = future.result()
                all_citing_metadata.extend(citings)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è {doi}: {e}")
            
            progress = (i + 1) / len(analyzed_dois)
            citing_progress.progress(progress)
            citing_status.text(f"–°–±–æ—Ä —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π: {i + 1}/{len(analyzed_dois)}")
    
    citing_progress.empty()
    citing_status.empty()
    
    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã
    unique_citing_dois = set(c['doi'] for c in all_citing_metadata if c.get('doi'))
    n_citing = len(unique_citing_dois)
    st.success(f"üìÑ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç: **{n_citing}**")
    overall_progress.progress(0.8)
    
    # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    overall_status.text("üìä –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    
    analyzed_stats = extract_stats_from_metadata(analyzed_metadata, journal_prefix=journal_prefix)
    citing_stats = extract_stats_from_metadata(all_citing_metadata, is_analyzed=False)
    enhanced_stats = enhanced_stats_calculation(analyzed_metadata, all_citing_metadata, state)
    
    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
    overlap_details = analyze_overlaps(analyzed_metadata, all_citing_metadata, state)
    
    citation_timing = calculate_citation_timing(analyzed_metadata, state)
    
    # –†–∞—Å—á–µ—Ç –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫ (–ù–û–í–û–ï)
    overall_status.text("üöÄ –†–∞—Å—á–µ—Ç –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫...")
    fast_metrics = calculate_all_fast_metrics(analyzed_metadata, all_citing_metadata, state, issn)
    
    overall_progress.progress(0.9)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    overall_status.text("üíæ –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'journal_analysis_{issn}_{timestamp}.xlsx'
    
    # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
    excel_buffer = io.BytesIO()
    create_enhanced_excel_report(analyzed_metadata, all_citing_metadata, analyzed_stats, citing_stats, enhanced_stats, citation_timing, overlap_details, fast_metrics, excel_buffer)
    
    excel_buffer.seek(0)
    state.excel_buffer = excel_buffer
    
    overall_progress.progress(1.0)
    overall_status.text("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    state.analysis_results = {
        'analyzed_stats': analyzed_stats,
        'citing_stats': citing_stats,
        'enhanced_stats': enhanced_stats,
        'citation_timing': citation_timing,
        'overlap_details': overlap_details,
        'fast_metrics': fast_metrics,  # –ù–û–í–û–ï
        'journal_name': journal_name,
        'issn': issn,
        'period': period_str,
        'n_analyzed': n_analyzed,
        'n_citing': n_citing
    }
    
    state.analysis_complete = True
    
    time.sleep(1)
    overall_progress.empty()
    overall_status.empty()

# === 20. –ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
def main():
    initialize_analysis_state()
    state = get_analysis_state()
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üî¨ Advanced Journal Analysis Tool")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –≤–≤–æ–¥–æ–º –¥–∞–Ω–Ω—ã—Ö
    with st.sidebar:
        st.header("üìù –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        issn = st.text_input(
            "ISSN –∂—É—Ä–Ω–∞–ª–∞:",
            value="2411-1414",
            help="–í–≤–µ–¥–∏—Ç–µ ISSN –∂—É—Ä–Ω–∞–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        )
        
        period = st.text_input(
            "–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:",
            value="2022-2024",
            help="–ü—Ä–∏–º–µ—Ä—ã: 2022, 2022-2024, 2022,2024"
        )
        
        st.markdown("---")
        st.header("üí° –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        st.info("""
        **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞:**
        - üìä H-index –∏ –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        - üë• –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π
        - üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        - üîó –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–∞–º–∏
        - ‚è±Ô∏è –í—Ä–µ–º—è –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        - üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        - üöÄ **–ù–û–í–û–ï: –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑ API**
        """)
        
        st.warning("""
        **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** 
        - –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç
        - –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ ISSN
        - –î–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è
        - –î–∞–Ω–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–µ —Ä–∞—Å—á–∏—Ç—ã–≤–∞–µ—Ç IF –∏ CiteScore. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–± —ç—Ç–∏—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ https://journal-metrics-app.streamlit.app
        - ¬©Chimica Techno Acta, https://chimicatechnoacta.ru / ¬©developed by daM
        """)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
        
        if st.button("–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", use_container_width=True):
            if not issn:
                st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ ISSN –∂—É—Ä–Ω–∞–ª–∞")
                return
                
            if not period:
                st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
                return
                
            with st.spinner("–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞..."):
                analyze_journal(issn, period)
    
    with col2:
        st.subheader("üì§ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        
        if state.analysis_complete and state.excel_buffer is not None:
            results = state.analysis_results
            
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å Excel –æ—Ç—á–µ—Ç",
                data=state.excel_buffer,
                file_name=f"journal_analysis_{results['issn']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if state.analysis_complete:
        st.markdown("---")
        st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        results = state.analysis_results
        
        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–ñ—É—Ä–Ω–∞–ª", results['journal_name'])
        with col2:
            st.metric("ISSN", results['issn'])
        with col3:
            st.metric("–ü–µ—Ä–∏–æ–¥", results['period'])
        with col4:
            st.metric("–°—Ç–∞—Ç–µ–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", results['n_analyzed'])
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        create_visualizations(
            results['analyzed_stats'],
            results['citing_stats'], 
            results['enhanced_stats'],
            results['citation_timing'],
            results['overlap_details'],
            results['fast_metrics']  # –ù–û–í–û–ï
        )
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.markdown("---")
        st.header("üìà –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        tab1, tab2, tab3, tab4 = st.tabs(["–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ —Å—Ç–∞—Ç—å–∏", "–¶–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã", "–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "–ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏"])  # –ù–û–í–ê–Ø –í–ö–õ–ê–î–ö–ê
        
        with tab1:
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π")
            stats = results['analyzed_stats']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π", stats['n_items'])
                st.metric("–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º", stats['single_authors'])
                st.metric("–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏", f"{stats['multi_country_pct']:.1f}%")
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π", stats['unique_affiliations_count'])
                
            with col2:
                st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫", stats['total_refs'])
                st.metric("–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{stats['self_cites_pct']:.1f}%")
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω", stats['unique_countries_count'])
                st.metric("–°—Ç–∞—Ç—å–∏ —Å ‚â•10 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏", stats['articles_with_10_citations'])
        
        with tab2:
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç")
            stats = results['citing_stats']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π", stats['n_items'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤", stats['unique_journals_count'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π", stats['unique_publishers_count'])
                
            with col2:
                st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫", stats['total_refs'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π", stats['unique_affiliations_count'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω", stats['unique_countries_count'])
        
        with tab3:
            st.subheader("–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ –∞–≤—Ç–æ—Ä–æ–≤ –Ω–∞ —Å—Ç–∞—Ç—å—é (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ)", 
                    f"{results['analyzed_stats']['auth_mean']:.1f}"
                )
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ)", 
                    f"{results['analyzed_stats']['ref_mean']:.1f}"
                )
                
            with col2:
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ –∞–≤—Ç–æ—Ä–æ–≤ –Ω–∞ —Å—Ç–∞—Ç—å—é (—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ)", 
                    f"{results['citing_stats']['auth_mean']:.1f}"
                )
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é (—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ)", 
                    f"{results['citing_stats']['ref_mean']:.1f}"
                )
        
        with tab4:  # –ù–û–í–ê–Ø –í–ö–õ–ê–î–ö–ê
            st.subheader("üöÄ –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–±–µ–∑ API –∑–∞–ø—Ä–æ—Å–æ–≤)")
            fast_metrics = results['fast_metrics']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Reference Age", f"{fast_metrics.get('ref_median_age', 'N/A')} –ª–µ—Ç")
                st.metric("JSCR", f"{fast_metrics.get('JSCR', 0)}%")
                st.metric("Cited Half-Life", f"{fast_metrics.get('cited_half_life_median', 'N/A')} –ª–µ—Ç")
                st.metric("FWCI", fast_metrics.get('FWCI', 0))
                
            with col2:
                st.metric("Citation Velocity", fast_metrics.get('citation_velocity', 0))
                st.metric("OA Impact Premium", f"{fast_metrics.get('OA_impact_premium', 0)}%")
                st.metric("Elite Index", f"{fast_metrics.get('elite_index', 0)}%")
                st.metric("Author Gini", fast_metrics.get('author_gini', 0))
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            st.subheader("–î–µ—Ç–∞–ª–∏ –±—ã—Å—Ç—Ä—ã—Ö –º–µ—Ç—Ä–∏–∫")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Reference Age:**")
                st.write(f"- –ú–µ–¥–∏–∞–Ω–∞: {fast_metrics.get('ref_median_age', 'N/A')} –ª–µ—Ç")
                st.write(f"- –°—Ä–µ–¥–Ω–µ–µ: {fast_metrics.get('ref_mean_age', 'N/A')} –ª–µ—Ç")
                st.write(f"- 25-75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å: {fast_metrics.get('ref_ages_25_75', ['N/A', 'N/A'])[0]}-{fast_metrics.get('ref_ages_25_75', ['N/A', 'N/A'])[1]} –ª–µ—Ç")
                st.write(f"- –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Å—ã–ª–æ–∫: {fast_metrics.get('total_refs_analyzed', 0)}")
                
                st.write("**Journal Self-Citation Rate:**")
                st.write(f"- –°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {fast_metrics.get('self_cites', 0)}")
                st.write(f"- –í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π: {fast_metrics.get('total_cites', 0)}")
                st.write(f"- –ü—Ä–æ—Ü–µ–Ω—Ç: {fast_metrics.get('JSCR', 0)}%")
            
            with col2:
                st.write("**Field-Weighted Citation Impact:**")
                st.write(f"- FWCI: {fast_metrics.get('FWCI', 0)}")
                st.write(f"- –û–±—â–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {fast_metrics.get('total_cites', 0)}")
                st.write(f"- –û–∂–∏–¥–∞–µ–º—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {fast_metrics.get('expected_cites', 0)}")
                
                st.write("**Diversity Balance Index:**")
                st.write(f"- DBI: {fast_metrics.get('DBI', 0)}")
                st.write(f"- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {fast_metrics.get('unique_concepts', 0)}")
                st.write(f"- –í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {fast_metrics.get('total_concept_mentions', 0)}")

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    main()
