import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import quote
import re
from collections import Counter, defaultdict
import json
from tqdm import tqdm
import sys
from datetime import datetime, timedelta
import io
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import base64
import os
import calendar
import pickle
import hashlib
import warnings
import asyncio
import aiohttp
import nest_asyncio

# –î–ª—è —Ä–∞–±–æ—Ç—ã async –≤ Streamlit
try:
    nest_asyncio.apply()
except:
    pass

warnings.filterwarnings('ignore')

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—É—á–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ---
EMAIL = st.secrets.get("EMAIL", "your.email@example.com") if hasattr(st, 'secrets') else "your.email@example.com"
MAX_WORKERS = 5
RETRIES = 3
DELAYS = [0.2, 0.5, 0.7, 1.0, 1.3, 1.5, 2.0]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫—ç—à–∞
CACHE_DIR = "journal_analysis_cache"
CACHE_DURATION = timedelta(hours=24)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
total_requests = 0
failed_requests = 0
request_lock = threading.Lock()
last_429_warning = ""

# --- –ö–ª–∞—Å—Å—ã –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
class AnalysisState:
    def __init__(self):
        self.crossref_cache = {}
        self.openalex_cache = {}
        self.unified_cache = {}
        self.citing_cache = defaultdict(list)
        self.institution_cache = {}
        self.journal_cache = {}
        self.analysis_results = None
        self.current_progress = 0
        self.progress_text = ""
        self.analysis_complete = False
        self.excel_buffer = None

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
def initialize_analysis_state():
    if 'analysis_state' not in st.session_state:
        st.session_state.analysis_state = AnalysisState()

def get_analysis_state():
    return st.session_state.analysis_state

# --- Rate Limiter ---
class RateLimiter:
    def __init__(self, calls_per_second=5):
        self.calls_per_second = calls_per_second
        self.timestamps = []
        self.lock = threading.Lock()
    
    def wait_if_needed(self):
        with self.lock:
            now = time.time()
            self.timestamps = [ts for ts in self.timestamps if now - ts < 1.0]
            
            if len(self.timestamps) >= self.calls_per_second:
                sleep_time = 1.0 - (now - self.timestamps[0])
                if sleep_time > 0:
                    time.sleep(sleep_time)
                self.timestamps = self.timestamps[1:]
            
            self.timestamps.append(now)

rate_limiter = RateLimiter(calls_per_second=8)

# --- –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ ---
class AdaptiveDelayer:
    def __init__(self):
        self.lock = threading.Lock()
        self.delay_index = 0

    def wait(self, success=True):
        with self.lock:
            if success:
                self.delay_index = 0
            else:
                self.delay_index = min(self.delay_index + 1, len(DELAYS) - 1)
            delay = DELAYS[self.delay_index]
            time.sleep(delay)
            return delay

delayer = AdaptiveDelayer()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
class JournalAnalyzerConfig:
    def __init__(self):
        self.email = EMAIL
        self.max_workers = MAX_WORKERS
        self.retries = RETRIES
        self.delays = DELAYS
        self.timeouts = {
            'crossref': 15,
            'openalex': 10,
            'batch': 30
        }
        self.batch_sizes = {
            'metadata': 10,
            'citations': 5
        }

config = JournalAnalyzerConfig()

# --- –§—É–Ω–∫—Ü–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è ---
def ensure_cache_dir():
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def get_cache_key(*args):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
    key_string = "_".join(str(arg) for arg in args)
    return hashlib.md5(key_string.encode()).hexdigest()

def save_to_cache(data, cache_key):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à"""
    ensure_cache_dir()
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
    cache_data = {
        'data': data,
        'timestamp': datetime.now()
    }
    with open(cache_file, 'wb') as f:
        pickle.dump(cache_data, f)

def load_from_cache(cache_key):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞"""
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
    if not os.path.exists(cache_file):
        return None
    try:
        with open(cache_file, 'rb') as f:
            cache_data = pickle.load(f)
        if datetime.now() - cache_data['timestamp'] < CACHE_DURATION:
            return cache_data['data']
        else:
            os.remove(cache_file)
            return None
    except:
        return None

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def update_progress(progress, text):
    state = get_analysis_state()
    state.current_progress = progress
    state.progress_text = text

# --- –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞ ---
def parse_period(period_str):
    years = set()
    parts = [p.strip() for p in period_str.replace(' ', '').split(',') if p.strip()]
    for part in parts:
        if '-' in part:
            try:
                s, e = map(int, part.split('-'))
                if 1900 <= s <= 2100 and 1900 <= e <= 2100 and s <= e:
                    years.update(range(s, e + 1))
                else:
                    st.warning(f"‚ö†Ô∏è –î–∏–∞–ø–∞–∑–æ–Ω –≤–Ω–µ 1900‚Äì2100 –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π: {part}")
            except ValueError:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞: {part}")
        else:
            try:
                y = int(part)
                if 1900 <= y <= 2100:
                    years.add(y)
                else:
                    st.warning(f"‚ö†Ô∏è –ì–æ–¥ –≤–Ω–µ 1900‚Äì2100: {y}")
            except ValueError:
                st.warning(f"‚ö†Ô∏è –ù–µ –≥–æ–¥: {part}")
    if not years:
        st.error("‚ùå –ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –≥–æ–¥–æ–≤.")
        return []
    return sorted(years)

# --- –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
def validate_and_clean_data(items):
    validated = []
    skipped_count = 0
    
    for item in items:
        if not item.get('DOI'):
            skipped_count += 1
            continue
            
        doi = item['DOI'].lower().strip()
        if not doi.startswith('10.'):
            skipped_count += 1
            continue
            
        date_parts = item.get('created', {}).get('date-parts', [[]])[0]
        if not date_parts or date_parts[0] < 1900:
            skipped_count += 1
            continue
            
        item['DOI'] = doi
        validated.append(item)
    
    if skipped_count > 0:
        st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count} —Å—Ç–∞—Ç–µ–π –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏")
    return validated

# === 1. –ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ ===
def get_journal_name(issn):
    state = get_analysis_state()
    if issn in state.crossref_cache.get('journals', {}):
        return state.crossref_cache['journals'][issn]
    url = f"https://api.openalex.org/sources?filter=issn:{issn}"
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if data['meta']['count'] > 0:
                    name = data['results'][0]['display_name']
                    if 'journals' not in state.crossref_cache:
                        state.crossref_cache['journals'] = {}
                    state.crossref_cache['journals'][issn] = name
                    delayer.wait(success=True)
                    return name
        except:
            pass
        delayer.wait(success=False)
    return "–ñ—É—Ä–Ω–∞–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"

# === 2. –ü–æ–ª—É—á–µ–Ω–∏–µ Crossref metadata ===
def get_crossref_metadata(doi, state):
    if doi in state.crossref_cache:
        return state.crossref_cache[doi]
    if not doi or doi == 'N/A':
        return None
    url = f"https://api.crossref.org/works/{quote(doi)}"
    headers = {'User-Agent': f"YourApp/1.0 (mailto:{EMAIL})"}
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, headers=headers, timeout=15)
            if resp.status_code == 200:
                data = resp.json()['message']
                state.crossref_cache[doi] = data
                delayer.wait(success=True)
                return data
        except:
            pass
        delayer.wait(success=False)
    return None

# === 3. –ü–æ–ª—É—á–µ–Ω–∏–µ OpenAlex metadata ===
def get_openalex_metadata(doi, state):
    if doi in state.openalex_cache:
        return state.openalex_cache[doi]
    if not doi or doi == 'N/A':
        return None
    normalized = doi if doi.startswith('http') else f"https://doi.org/{doi}"
    url = f"https://api.openalex.org/works/{quote(normalized)}"
    for _ in range(RETRIES):
        try:
            rate_limiter.wait_if_needed()
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                state.openalex_cache[doi] = data
                delayer.wait(success=True)
                return data
        except:
            pass
        delayer.wait(success=False)
    return None

# === 4. –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ===
def get_unified_metadata(args):
    doi, state = args
    if doi in state.unified_cache:
        return state.unified_cache[doi]
    
    if not doi or doi == 'N/A':
        return {'crossref': None, 'openalex': None}
    
    cr_data = get_crossref_metadata(doi, state)
    oa_data = get_openalex_metadata(doi, state)
    
    result = {'crossref': cr_data, 'openalex': oa_data}
    state.unified_cache[doi] = result
    return result

# === 5. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö DOI –∏ –∏—Ö metadata ===
def get_citing_dois_and_metadata(args):
    analyzed_doi, state = args
    if analyzed_doi in state.citing_cache:
        return state.citing_cache[analyzed_doi]
    citing_list = []
    oa_data = get_openalex_metadata(analyzed_doi, state)
    if not oa_data or oa_data.get('cited_by_count', 0) == 0:
        state.citing_cache[analyzed_doi] = citing_list
        return citing_list
    work_id = oa_data['id'].split('/')[-1]
    url = f"https://api.openalex.org/works?filter=cites:{work_id}&per-page=100"
    cursor = "*"
    
    while cursor:
        success = False
        for _ in range(RETRIES):
            try:
                rate_limiter.wait_if_needed()
                resp = requests.get(f"{url}&cursor={cursor}", timeout=15)
                if resp.status_code == 200:
                    data = resp.json()
                    for w in data.get('results', []):
                        c_doi = w.get('doi')
                        if c_doi:
                            if c_doi not in state.crossref_cache:
                                get_crossref_metadata(c_doi, state)
                            if c_doi not in state.openalex_cache:
                                get_openalex_metadata(c_doi, state)
                            citing_list.append({
                                'doi': c_doi,
                                'pub_date': w.get('publication_date'),
                                'crossref': state.crossref_cache.get(c_doi),
                                'openalex': state.openalex_cache.get(c_doi)
                            })
                    cursor = data['meta'].get('next_cursor')
                    delayer.wait(success=True)
                    success = True
                    break
            except:
                pass
            delayer.wait(success=False)
        if not success:
            break
    state.citing_cache[analyzed_doi] = citing_list
    return citing_list

# === 6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π –∏ —Å—Ç—Ä–∞–Ω ===
def extract_affiliations_and_countries(openalex_data):
    affiliations = set()
    countries = set()
    authors_list = []
    
    if not openalex_data:
        return authors_list, list(affiliations), list(countries)
    
    if 'authorships' in openalex_data:
        for auth in openalex_data['authorships']:
            author_name = auth.get('author', {}).get('display_name', 'Unknown')
            authors_list.append(author_name)
            
            for inst in auth.get('institutions', []):
                inst_name = inst.get('display_name')
                country_code = inst.get('country_code')
                
                if inst_name:
                    affiliations.add(inst_name)
                if country_code:
                    countries.add(country_code.upper())
    
    return authors_list, list(affiliations), list(countries)

# === 7. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∂—É—Ä–Ω–∞–ª–µ ===
def extract_journal_info(metadata):
    journal_info = {
        'issn': [],
        'journal_name': '',
        'publisher': ''
    }
    
    if not metadata:
        return journal_info
    
    cr = metadata.get('crossref')
    if cr:
        journal_info['issn'] = cr.get('ISSN', [])
        journal_info['journal_name'] = cr.get('container-title', [''])[0] if cr.get('container-title') else ''
        journal_info['publisher'] = cr.get('publisher', '')
    
    oa = metadata.get('openalex')
    if oa:
        host_venue = oa.get('host_venue', {})
        if host_venue:
            if not journal_info['journal_name']:
                journal_info['journal_name'] = host_venue.get('display_name', '')
            if not journal_info['publisher']:
                journal_info['publisher'] = host_venue.get('publisher', '')
            if not journal_info['issn']:
                journal_info['issn'] = host_venue.get('issn', [])
    
    return journal_info

# === 8. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref ===
def fetch_articles_by_issn_period(issn, from_date, until_date):
    base_url = "https://api.crossref.org/works"
    items = []
    cursor = "*"
    params = {
        'filter': f'issn:{issn},from-pub-date:{from_date},until-pub-date:{until_date}',
        'rows': 1000,
        'cursor': cursor,
        'mailto': EMAIL
    }
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    progress_container = st.container()
    
    with progress_container:
        st.info("üì• –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö **Crossref** –∏ **OpenAlex**. –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Å–ª—É—á–∞–µ –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π –∏–ª–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è '–±—ã—Å—Ç—Ä–æ–π' —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–º–µ–Ω—å—à–∏—Ç—å –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞...")
    
    while cursor:
        params['cursor'] = cursor
        success = False
        for _ in range(RETRIES):
            try:
                rate_limiter.wait_if_needed()
                resp = requests.get(base_url, params=params, timeout=15)
                if resp.status_code == 200:
                    data = resp.json()
                    new_items = data['message']['items']
                    items.extend(new_items)
                    cursor = data['message'].get('next-cursor')
                    
                    status_text.text(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π...")
                    if cursor:
                        progress = min(len(items) / (len(items) + 100), 0.95)
                        progress_bar.progress(progress)
                    
                    delayer.wait(success=True)
                    success = True
                    break
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
            delayer.wait(success=False)
        if not success:
            break
        if not new_items:
            break
    
    progress_bar.progress(1.0)
    status_text.text(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π")
    time.sleep(0.5)
    progress_bar.empty()
    status_text.empty()
    progress_container.empty()
    
    return items

# === 9. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ DOI ===
def get_doi_prefix(doi):
    if not doi or doi == 'N/A':
        return ''
    return doi.split('/')[0] if '/' in doi else doi[:7]

# === 10. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º ===
def process_with_progress(items, func, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞", unit="—ç–ª–µ–º–µ–Ω—Ç–æ–≤"):
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(func, item): item for item in items}
        
        for i, future in enumerate(as_completed(futures)):
            try:
                results.append(future.result())
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –≤ {desc}: {e}")
                results.append(None)
            
            progress = (i + 1) / len(items)
            progress_bar.progress(progress)
            status_text.text(f"{desc}: {i + 1}/{len(items)}")
    
    progress_bar.empty()
    status_text.empty()
    return results

# === 11. –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏ ===
def analyze_overlaps(analyzed_metadata, citing_metadata, state):
    """–ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏"""
    
    overlap_details = []
    
    for analyzed in analyzed_metadata:
        if not analyzed or not analyzed.get('crossref'):
            continue
            
        analyzed_doi = analyzed['crossref'].get('DOI')
        if not analyzed_doi:
            continue
            
        # –ü–æ–ª—É—á–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã
        analyzed_authors, analyzed_affiliations, _ = extract_affiliations_and_countries(analyzed.get('openalex'))
        analyzed_authors_set = set(analyzed_authors)
        analyzed_affiliations_set = set(analyzed_affiliations)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã
        citings = get_citing_dois_and_metadata((analyzed_doi, state))
        
        for citing in citings:
            if not citing or not citing.get('openalex'):
                continue
                
            citing_doi = citing.get('doi')
            if not citing_doi:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã
            citing_authors, citing_affiliations, _ = extract_affiliations_and_countries(citing.get('openalex'))
            citing_authors_set = set(citing_authors)
            citing_affiliations_set = set(citing_affiliations)
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
            common_authors = analyzed_authors_set.intersection(citing_authors_set)
            common_affiliations = analyzed_affiliations_set.intersection(citing_affiliations_set)
            
            if common_authors or common_affiliations:
                overlap_details.append({
                    'analyzed_doi': analyzed_doi,
                    'citing_doi': citing_doi,
                    'common_authors': list(common_authors),
                    'common_affiliations': list(common_affiliations),
                    'common_authors_count': len(common_authors),
                    'common_affiliations_count': len(common_affiliations)
                })
    
    return overlap_details

# === 12. –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π ===
def analyze_citation_accumulation(analyzed_metadata, state):
    accumulation_data = defaultdict(lambda: defaultdict(int))
    yearly_citations = defaultdict(int)
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if not analyzed_doi:
                continue
                
            pub_year = analyzed['crossref'].get('published', {}).get('date-parts', [[0]])[0][0]
            if not pub_year:
                continue
            
            citings = get_citing_dois_and_metadata((analyzed_doi, state))
            
            for citing in citings:
                if citing.get('openalex'):
                    cite_year = citing['openalex'].get('publication_year', 0)
                    if cite_year >= pub_year:
                        yearly_citations[cite_year] += 1
                        years_since_pub = cite_year - pub_year
                        if years_since_pub >= 0:
                            for year in range(years_since_pub + 1):
                                accumulation_data[pub_year][year] += 1
    
    accumulation_curves = {}
    for pub_year, yearly_counts in accumulation_data.items():
        sorted_years = sorted(yearly_counts.keys())
        cumulative_counts = []
        current_total = 0
        for year in sorted_years:
            current_total += yearly_counts[year]
            cumulative_counts.append({
                'years_since_publication': year,
                'cumulative_citations': current_total
            })
        accumulation_curves[pub_year] = cumulative_counts
    
    yearly_stats = []
    for year in sorted(yearly_citations.keys()):
        yearly_stats.append({
            'year': year,
            'citations_count': yearly_citations[year]
        })
    
    return {
        'accumulation_curves': dict(accumulation_curves),
        'yearly_citations': yearly_stats,
        'total_years_covered': len(yearly_citations)
    }

# === 13. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===
def extract_stats_from_metadata(metadata_list, is_analyzed=True, journal_prefix=''):
    total_refs = 0
    refs_with_doi = 0
    refs_without_doi = 0
    self_cites = 0
    ref_counts = []
    author_counts = []
    single_authors = 0
    multi_authors_gt10 = 0
    author_freq = Counter()
    pub_dates = []
    
    articles_with_10_citations = 0
    articles_with_50_citations = 0
    articles_with_100_citations = 0
    articles_with_200_citations = 0

    affiliations_freq = Counter()
    countries_freq = Counter()
    single_country_articles = 0
    multi_country_articles = 0
    no_country_articles = 0
    all_authors = []
    all_affiliations = []
    all_countries = []
    
    journal_freq = Counter()
    publisher_freq = Counter()

    for meta in metadata_list:
        if not meta:
            continue

        cr = meta.get('crossref')
        if cr:
            refs = cr.get('reference', [])
            total_refs += len(refs)
            for ref in refs:
                ref_doi = ref.get('DOI', '')
                if ref_doi:
                    refs_with_doi += 1
                    if get_doi_prefix(ref_doi) == journal_prefix:
                        self_cites += 1
                else:
                    refs_without_doi += 1
            ref_counts.append(len(refs))

            authors = cr.get('author', [])
            num_auth = len(authors)
            author_counts.append(num_auth)
            if num_auth == 1:
                single_authors += 1
            if num_auth > 10:
                multi_authors_gt10 += 1

            for auth in authors:
                family = auth.get('family', '').strip().title()
                given = auth.get('given', '').strip()
                initials = '.'.join([c + '.' for c in given if c.isupper()]) if given else ''
                if initials:
                    name = f"{family} {initials}"
                else:
                    name = family or 'Unknown'
                author_freq[name] += 1

            date_parts = cr.get('published', {}).get('date-parts', [[datetime.now().year]])[0]
            pub_date = datetime(date_parts[0], date_parts[1] if len(date_parts)>1 else 1, date_parts[2] if len(date_parts)>2 else 1)
            pub_dates.append(pub_date)
            
            journal_name = cr.get('container-title', [''])[0] if cr.get('container-title') else ''
            publisher = cr.get('publisher', '')
            if journal_name:
                journal_freq[journal_name] += 1
            if publisher:
                publisher_freq[publisher] += 1

        oa = meta.get('openalex')
        if oa:
            authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
            
            all_authors.extend(authors_list)
            all_affiliations.extend(affiliations_list)
            all_countries.extend(countries_list)
            
            for aff in affiliations_list:
                affiliations_freq[aff] += 1
            for country in countries_list:
                countries_freq[country] += 1
            
            unique_countries = set(countries_list)
            if len(unique_countries) == 0:
                no_country_articles += 1
            elif len(unique_countries) == 1:
                single_country_articles += 1
            elif len(unique_countries) > 1:
                multi_country_articles += 1
            
            host_venue = oa.get('host_venue', {})
            if host_venue:
                journal_name = host_venue.get('display_name', '')
                publisher = host_venue.get('publisher', '')
                if journal_name and journal_name not in journal_freq:
                    journal_freq[journal_name] += 1
                if publisher and publisher not in publisher_freq:
                    publisher_freq[publisher] += 1
            
            if is_analyzed:
                citation_count = oa.get('cited_by_count', 0)
                if citation_count >= 10:
                    articles_with_10_citations += 1
                if citation_count >= 50:
                    articles_with_50_citations += 1
                if citation_count >= 100:
                    articles_with_100_citations += 1
                if citation_count >= 200:
                    articles_with_200_citations += 1

    n_items = len(metadata_list)

    refs_with_doi_pct = (refs_with_doi / total_refs * 100) if total_refs > 0 else 0
    refs_without_doi_pct = (refs_without_doi / total_refs * 100) if total_refs > 0 else 0
    self_cites_pct = (self_cites / total_refs * 100) if total_refs > 0 else 0

    ref_min = min(ref_counts) if ref_counts else 0
    ref_max = max(ref_counts) if ref_counts else 0
    ref_mean = sum(ref_counts)/n_items if n_items > 0 else 0
    ref_median = sorted(ref_counts)[n_items//2] if n_items > 0 else 0

    auth_min = min(author_counts) if author_counts else 0
    auth_max = max(author_counts) if author_counts else 0
    auth_mean = sum(author_counts)/n_items if n_items > 0 else 0
    auth_median = sorted(author_counts)[n_items//2] if n_items > 0 else 0

    all_authors_sorted = author_freq.most_common()

    all_affiliations_sorted = affiliations_freq.most_common()
    all_countries_sorted = countries_freq.most_common()
    
    single_country_pct = (single_country_articles / n_items * 100) if n_items > 0 else 0
    multi_country_pct = (multi_country_articles / n_items * 100) if n_items > 0 else 0
    no_country_pct = (no_country_articles / n_items * 100) if n_items > 0 else 0

    all_journals_sorted = journal_freq.most_common()
    all_publishers_sorted = publisher_freq.most_common()

    return {
        'n_items': n_items,
        'total_refs': total_refs,
        'refs_with_doi': refs_with_doi, 'refs_with_doi_pct': refs_with_doi_pct,
        'refs_without_doi': refs_without_doi, 'refs_without_doi_pct': refs_without_doi_pct,
        'self_cites': self_cites, 'self_cites_pct': self_cites_pct,
        'ref_min': ref_min, 'ref_max': ref_max, 'ref_mean': ref_mean, 'ref_median': ref_median,
        'auth_min': auth_min, 'auth_max': auth_max, 'auth_mean': auth_mean, 'auth_median': auth_median,
        'single_authors': single_authors,
        'multi_authors_gt10': multi_authors_gt10,
        'all_authors': all_authors_sorted,
        'pub_dates': pub_dates,
        'articles_with_10_citations': articles_with_10_citations,
        'articles_with_50_citations': articles_with_50_citations,
        'articles_with_100_citations': articles_with_100_citations,
        'articles_with_200_citations': articles_with_200_citations,
        'all_affiliations': all_affiliations_sorted,
        'all_countries': all_countries_sorted,
        'all_authors_list': all_authors,
        'all_affiliations_list': all_affiliations,
        'all_countries_list': all_countries,
        'single_country_articles': single_country_articles, 
        'single_country_pct': single_country_pct,
        'multi_country_articles': multi_country_articles, 
        'multi_country_pct': multi_country_pct,
        'no_country_articles': no_country_articles,
        'no_country_pct': no_country_pct,
        'total_affiliations_count': len(all_affiliations),
        'unique_affiliations_count': len(set(all_affiliations)),
        'unique_countries_count': len(set(all_countries)),
        'all_journals': all_journals_sorted,
        'all_publishers': all_publishers_sorted,
        'unique_journals_count': len(journal_freq),
        'unique_publishers_count': len(publisher_freq)
    }

# === 14. –†–∞—Å—á–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ===
def enhanced_stats_calculation(analyzed_metadata, citing_metadata, state):
    citation_network = defaultdict(list)
    citation_counts = []
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if analyzed_doi:
                analyzed_year = analyzed['crossref'].get('published', {}).get('date-parts', [[0]])[0][0]
                citings = get_citing_dois_and_metadata((analyzed_doi, state))
                citation_counts.append(len(citings))
                
                for citing in citings:
                    if citing.get('openalex'):
                        citing_year = citing['openalex'].get('publication_year', 0)
                        citation_network[analyzed_year].append(citing_year)
    
    citation_counts.sort(reverse=True)
    h_index = 0
    for i, count in enumerate(citation_counts):
        if count >= i + 1:
            h_index = i + 1
        else:
            break
    
    return {
        'h_index': h_index,
        'citation_network': dict(citation_network),
        'avg_citations_per_article': sum(citation_counts) / len(citation_counts) if citation_counts else 0,
        'max_citations': max(citation_counts) if citation_counts else 0,
        'min_citations': min(citation_counts) if citation_counts else 0,
        'total_citations': sum(citation_counts),
        'articles_with_citations': len([c for c in citation_counts if c > 0]),
        'articles_without_citations': len([c for c in citation_counts if c == 0])
    }

# === 15. –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
def calculate_citation_timing_stats(analyzed_metadata, state):
    all_days_to_first_citation = []
    citation_timing_stats = {}
    first_citation_details = []
    
    for analyzed in analyzed_metadata:
        if analyzed and analyzed.get('crossref'):
            analyzed_doi = analyzed['crossref'].get('DOI')
            if not analyzed_doi:
                continue
                
            analyzed_date_parts = analyzed['crossref'].get('published', {}).get('date-parts', [[]])[0]
            if not analyzed_date_parts or len(analyzed_date_parts) < 1:
                continue
                
            analyzed_year = analyzed_date_parts[0]
            analyzed_month = analyzed_date_parts[1] if len(analyzed_date_parts) > 1 else 1
            analyzed_day = analyzed_date_parts[2] if len(analyzed_date_parts) > 2 else 1
            
            try:
                analyzed_date = datetime(analyzed_year, analyzed_month, analyzed_day)
            except:
                continue
            
            citings = get_citing_dois_and_metadata((analyzed_doi, state))
            citation_dates = []
            
            for citing in citings:
                if citing.get('pub_date'):
                    try:
                        cite_date = datetime.fromisoformat(citing['pub_date'].replace('Z', '+00:00'))
                        citation_dates.append((cite_date, citing.get('doi')))
                    except:
                        continue
            
            if citation_dates:
                first_citation_date, first_citing_doi = min(citation_dates, key=lambda x: x[0])
                days_to_first_citation = (first_citation_date - analyzed_date).days
                if days_to_first_citation >= 0:
                    all_days_to_first_citation.append(days_to_first_citation)
                    first_citation_details.append({
                        'analyzed_doi': analyzed_doi,
                        'citing_doi': first_citing_doi,
                        'analyzed_date': analyzed_date,
                        'first_citation_date': first_citation_date,
                        'days_to_first_citation': days_to_first_citation
                    })
    
    if all_days_to_first_citation:
        citation_timing_stats = {
            'min_days_to_first_citation': min(all_days_to_first_citation),
            'max_days_to_first_citation': max(all_days_to_first_citation),
            'mean_days_to_first_citation': np.mean(all_days_to_first_citation),
            'median_days_to_first_citation': np.median(all_days_to_first_citation),
            'articles_with_citation_timing_data': len(all_days_to_first_citation),
            'first_citation_details': first_citation_details
        }
    else:
        citation_timing_stats = {
            'min_days_to_first_citation': 0,
            'max_days_to_first_citation': 0,
            'mean_days_to_first_citation': 0,
            'median_days_to_first_citation': 0,
            'articles_with_citation_timing_data': 0,
            'first_citation_details': []
        }
    
    return citation_timing_stats

# === 16. –ö–û–†–†–ï–ö–¢–ù–´–ô –†–ê–°–ß–ï–¢ Impact Factor –∏ CiteScore ===
def validate_issn(issn):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ ISSN"""
    if not issn:
        return False
    pattern = r'^\d{4}-\d{3}[\dXx]$'
    return re.match(pattern, issn) is not None

def get_seasonal_coefficients(journal_field="general"):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    seasonal_patterns = {
        "natural_sciences": {
            1: 0.85, 2: 1.05, 3: 1.25, 4: 1.15, 5: 1.00, 6: 0.95,
            7: 0.70, 8: 0.75, 9: 1.30, 10: 1.20, 11: 1.15, 12: 0.65
        },
        "general": {
            1: 0.90, 2: 1.15, 3: 1.20, 4: 1.15, 5: 1.00, 6: 1.00,
            7: 0.70, 8: 0.80, 9: 1.20, 10: 1.25, 11: 1.15, 12: 0.60
        }
    }
    return seasonal_patterns.get(journal_field, seasonal_patterns["general"])

def calculate_weighted_multiplier(current_date, seasonal_coefficients, method="balanced"):
    """–†–∞—Å—á–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è"""
    current_year = current_date.year
    current_month = current_date.month
    days_passed = (current_date - date(current_year, 1, 1)).days + 1

    weighted_passed = 0
    for month in range(1, current_month + 1):
        _, month_days = calendar.monthrange(current_year, month)
        if month == current_month:
            month_days = current_date.day
        weighted_passed += seasonal_coefficients[month] * month_days

    total_weighted_year = sum(
        seasonal_coefficients[month] * calendar.monthrange(current_year, month)[1]
        for month in range(1, 13)
    )

    base_multiplier = total_weighted_year / weighted_passed if weighted_passed > 0 else 1.0

    if method == "conservative":
        return max(1.0, base_multiplier * 0.9)
    elif method == "optimistic":
        return max(1.0, base_multiplier * 1.1)
    else:
        return max(1.0, base_multiplier)

def detect_journal_field(issn, journal_name):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∂—É—Ä–Ω–∞–ª–∞"""
    field_keywords = {
        "natural_sciences": ['nature', 'science', 'physical', 'chemistry', 'physics'],
        "general": ['general', 'techno', 'acta']
    }
    journal_name_lower = journal_name.lower()
    for field, keywords in field_keywords.items():
        for keyword in keywords:
            if keyword in journal_name_lower:
                return field
    return "general"

def calculate_correct_impact_factor_and_citescore(issn, journal_name, analyzed_metadata, state):
    """–ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç Impact Factor –∏ CiteScore –ø–æ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –∫–æ–¥–∞"""
    
    try:
        current_date = datetime.now().date()
        current_year = current_date.year
        journal_field = detect_journal_field(issn, journal_name)

        # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è Impact Factor (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∑–∞ 2 –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≥–æ–¥–∞)
        if_publication_years = [current_year - 2, current_year - 1]
        
        # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è CiteScore (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∑–∞ 4 –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≥–æ–¥–∞)
        cs_publication_years = list(range(current_year - 3, current_year + 1))

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π –¥–ª—è IF
        if_items = []
        for meta in analyzed_metadata:
            if meta and meta.get('crossref'):
                cr = meta['crossref']
                pub_year = cr.get('published', {}).get('date-parts', [[0]])[0][0]
                if pub_year in if_publication_years:
                    if_items.append({
                        'DOI': cr.get('DOI', 'N/A'),
                        'published': {'date-parts': [[pub_year]]},
                        'is-referenced-by-count': cr.get('is-referenced-by-count', 0),
                        'crossref_data': cr,
                        'openalex_data': meta.get('openalex')
                    })

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–µ–π –¥–ª—è CiteScore
        cs_items = []
        for meta in analyzed_metadata:
            if meta and meta.get('crossref'):
                cr = meta['crossref']
                pub_year = cr.get('published', {}).get('date-parts', [[0]])[0][0]
                if pub_year in cs_publication_years:
                    cs_items.append({
                        'DOI': cr.get('DOI', 'N/A'),
                        'published': {'date-parts': [[pub_year]]},
                        'is-referenced-by-count': cr.get('is-referenced-by-count', 0),
                        'crossref_data': cr,
                        'openalex_data': meta.get('openalex')
                    })

        B_if = len(if_items)
        B_cs = len(cs_items)
        
        st.info(f"üìä –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ Impact Factor: {B_if} —Å—Ç–∞—Ç–µ–π –∑–∞ {if_publication_years}")
        st.info(f"üìä –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ CiteScore: {B_cs} —Å—Ç–∞—Ç–µ–π –∑–∞ {cs_publication_years}")

        if B_if == 0 or B_cs == 0:
            st.warning("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫")
            return None

        # –†–∞—Å—á–µ—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π —á–µ—Ä–µ–∑ OpenAlex –¥–ª—è IF
        A_if_current = 0
        if_citation_data = []
        
        for item in if_items:
            doi = item['DOI']
            crossref_cites = item['is-referenced-by-count']
            
            if doi != 'N/A':
                # –ü–æ–ª—É—á–∞–µ–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ OpenAlex
                oa_data = get_openalex_metadata(doi, state)
                if oa_data:
                    openalex_count = oa_data.get('cited_by_count', 0)
                    A_if_current += openalex_count
                    
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item['published']['date-parts'][0][0],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': openalex_count,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': openalex_count
                    })
                else:
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item['published']['date-parts'][0][0],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
            else:
                if_citation_data.append({
                    'DOI': doi,
                    '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item['published']['date-parts'][0][0],
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                })

        # –†–∞—Å—á–µ—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è CiteScore (–∏—Å–ø–æ–ª—å–∑—É–µ–º Crossref)
        A_cs_current = sum(item['is-referenced-by-count'] for item in cs_items)
        cs_citation_data = [
            {
                'DOI': item['DOI'],
                '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item['published']['date-parts'][0][0],
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': item['is-referenced-by-count'],
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
            } for item in cs_items
        ]

        # –†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        current_if = A_if_current / B_if if B_if > 0 else 0
        current_citescore = A_cs_current / B_cs if B_cs > 0 else 0

        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
        seasonal_coefficients = get_seasonal_coefficients(journal_field)
        multiplier_conservative = calculate_weighted_multiplier(current_date, seasonal_coefficients, "conservative")
        multiplier_balanced = calculate_weighted_multiplier(current_date, seasonal_coefficients, "balanced")
        multiplier_optimistic = calculate_weighted_multiplier(current_date, seasonal_coefficients, "optimistic")

        if_forecasts = {
            'conservative': current_if * multiplier_conservative,
            'balanced': current_if * multiplier_balanced,
            'optimistic': current_if * multiplier_optimistic
        }

        citescore_forecasts = {
            'conservative': current_citescore * multiplier_conservative,
            'balanced': current_citescore * multiplier_balanced,
            'optimistic': current_citescore * multiplier_optimistic
        }

        return {
            'current_if': current_if,
            'current_citescore': current_citescore,
            'if_forecasts': if_forecasts,
            'citescore_forecasts': citescore_forecasts,
            'multipliers': {
                'conservative': multiplier_conservative,
                'balanced': multiplier_balanced,
                'optimistic': multiplier_optimistic
            },
            'total_cites_if': A_if_current,
            'total_articles_if': B_if,
            'total_cites_cs': A_cs_current,
            'total_articles_cs': B_cs,
            'citation_distribution': dict(seasonal_coefficients),
            'if_citation_data': if_citation_data,
            'cs_citation_data': cs_citation_data,
            'analysis_date': current_date,
            'if_publication_years': if_publication_years,
            'cs_publication_years': cs_publication_years,
            'seasonal_coefficients': seasonal_coefficients,
            'journal_field': journal_field,
            'self_citation_rate': 0.05,
            'total_self_citations': int(A_if_current * 0.05),
            'issn': issn,
            'journal_name': journal_name
        }

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫: {e}")
        import traceback
        traceback.print_exc()
        return None

# === 17. –†–∞—Å—á–µ—Ç IF –∏ –¥–Ω–µ–π (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø) ===
def calculate_if_and_days(analyzed_metadata, all_citing_metadata, current_date, state, issn, journal_name):
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ IF —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ª–æ–≥–∏–∫–∏"""
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç IF –∏ CiteScore
    metrics_data = calculate_correct_impact_factor_and_citescore(issn, journal_name, analyzed_metadata, state)
    
    if not metrics_data:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        return {
            'if_value': 0.0,
            'citescore_value': 0.0,
            'c_num': 0,
            'p_den': 0,
            'cs_c_num': 0,
            'cs_p_den': 0,
            'citation_years': [],
            'publication_years': [],
            'cs_publication_years': [],
            'days_min': 0,
            'days_max': 0,
            'days_mean': 0,
            'days_median': 0,
            'articles_with_timing_data': 0,
            'first_citation_details': [],
            'accumulation_curves': {},
            'yearly_citations': [],
            'total_years_covered': 0,
            'if_forecasts': {},
            'citescore_forecasts': {},
            'multipliers': {},
            'citation_distribution': {},
            'journal_field': 'general'
        }
    
    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É)
    timing_stats = calculate_citation_timing_stats(analyzed_metadata, state)
    accumulation_stats = analyze_citation_accumulation(analyzed_metadata, state)
    
    return {
        'if_value': metrics_data['current_if'],
        'citescore_value': metrics_data['current_citescore'],
        'c_num': metrics_data['total_cites_if'],
        'p_den': metrics_data['total_articles_if'],
        'cs_c_num': metrics_data['total_cites_cs'],
        'cs_p_den': metrics_data['total_articles_cs'],
        'citation_years': [current_date.year - 1, current_date.year],
        'publication_years': metrics_data['if_publication_years'],
        'cs_publication_years': metrics_data['cs_publication_years'],
        'days_min': timing_stats['min_days_to_first_citation'],
        'days_max': timing_stats['max_days_to_first_citation'],
        'days_mean': timing_stats['mean_days_to_first_citation'],
        'days_median': timing_stats['median_days_to_first_citation'],
        'articles_with_timing_data': timing_stats['articles_with_citation_timing_data'],
        'first_citation_details': timing_stats['first_citation_details'],
        'accumulation_curves': accumulation_stats['accumulation_curves'],
        'yearly_citations': accumulation_stats['yearly_citations'],
        'total_years_covered': accumulation_stats['total_years_covered'],
        'if_forecasts': metrics_data['if_forecasts'],
        'citescore_forecasts': metrics_data['citescore_forecasts'],
        'multipliers': metrics_data['multipliers'],
        'citation_distribution': metrics_data['citation_distribution'],
        'journal_field': metrics_data['journal_field']
    }

# === 18. –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞ (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø) ===
def create_enhanced_excel_report(analyzed_data, citing_data, analyzed_stats, citing_stats, enhanced_stats, if_days, overlap_details, filename):
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        # –õ–∏—Å—Ç 1: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ —Å—Ç–∞—Ç—å–∏
        analyzed_list = []
        for item in analyzed_data:
            if item and item.get('crossref'):
                cr = item['crossref']
                oa = item.get('openalex', {})
                authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
                journal_info = extract_journal_info(item)
                
                analyzed_list.append({
                    'DOI': cr.get('DOI', ''),
                    '–ù–∞–∑–≤–∞–Ω–∏–µ': cr.get('title', [''])[0] if cr.get('title') else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è',
                    '–ê–≤—Ç–æ—Ä—ã_Crossref': '; '.join([f"{a.get('given', '')} {a.get('family', '')}" for a in cr.get('author', [])]),
                    '–ê–≤—Ç–æ—Ä—ã_OpenAlex': '; '.join(authors_list),
                    '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(affiliations_list),
                    '–°—Ç—Ä–∞–Ω—ã': '; '.join(countries_list),
                    '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': cr.get('published', {}).get('date-parts', [[0]])[0][0],
                    '–ñ—É—Ä–Ω–∞–ª': journal_info['journal_name'],
                    '–ò–∑–¥–∞—Ç–µ–ª—å': journal_info['publisher'],
                    'ISSN': '; '.join(journal_info['issn']),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫': cr.get('reference-count', 0),
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Crossref': cr.get('is-referenced-by-count', 0),
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAlex': oa.get('cited_by_count', 0),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤': len(cr.get('author', [])),
                    '–¢–∏–ø —Ä–∞–±–æ—Ç—ã': cr.get('type', '')
                })
        
        if analyzed_list:
            analyzed_df = pd.DataFrame(analyzed_list)
            analyzed_df.to_excel(writer, sheet_name='–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ_—Å—Ç–∞—Ç—å–∏', index=False)

        # –õ–∏—Å—Ç 2: –¶–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã
        citing_list = []
        for item in citing_data:
            if item and item.get('crossref'):
                cr = item['crossref']
                oa = item.get('openalex', {})
                authors_list, affiliations_list, countries_list = extract_affiliations_and_countries(oa)
                journal_info = extract_journal_info(item)
                
                citing_list.append({
                    'DOI': cr.get('DOI', ''),
                    '–ù–∞–∑–≤–∞–Ω–∏–µ': cr.get('title', [''])[0] if cr.get('title') else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è',
                    '–ê–≤—Ç–æ—Ä—ã_Crossref': '; '.join([f"{a.get('given', '')} {a.get('family', '')}" for a in cr.get('author', [])]),
                    '–ê–≤—Ç–æ—Ä—ã_OpenAlex': '; '.join(authors_list),
                    '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(affiliations_list),
                    '–°—Ç—Ä–∞–Ω—ã': '; '.join(countries_list),
                    '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': cr.get('published', {}).get('date-parts', [[0]])[0][0],
                    '–ñ—É—Ä–Ω–∞–ª': journal_info['journal_name'],
                    '–ò–∑–¥–∞—Ç–µ–ª—å': journal_info['publisher'],
                    'ISSN': '; '.join(journal_info['issn']),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫': cr.get('reference-count', 0),
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Crossref': cr.get('is-referenced-by-count', 0),
                    '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAlex': oa.get('cited_by_count', 0),
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤': len(cr.get('author', [])),
                    '–¢–∏–ø —Ä–∞–±–æ—Ç—ã': cr.get('type', '')
                })
        
        if citing_list:
            citing_df = pd.DataFrame(citing_list)
            citing_df.to_excel(writer, sheet_name='–¶–∏—Ç–∏—Ä—É—é—â–∏–µ_—Ä–∞–±–æ—Ç—ã', index=False)

        # –õ–∏—Å—Ç 3: –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç
        overlap_list = []
        for overlap in overlap_details:
            overlap_list.append({
                'DOI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã': overlap['analyzed_doi'],
                'DOI —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã': overlap['citing_doi'],
                '–°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∞–≤—Ç–æ—Ä—ã': '; '.join(overlap['common_authors']),
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∞–≤—Ç–æ—Ä–æ–≤': overlap['common_authors_count'],
                '–°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏': '; '.join(overlap['common_affiliations']),
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π': overlap['common_affiliations_count']
            })
        
        if overlap_list:
            overlap_df = pd.DataFrame(overlap_list)
            overlap_df.to_excel(writer, sheet_name='–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è_—Ä–∞–±–æ—Ç', index=False)

        # –õ–∏—Å—Ç 4: –í—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        first_citation_list = []
        for detail in if_days.get('first_citation_details', []):
            first_citation_list.append({
                'DOI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π —Ä–∞–±–æ—Ç—ã': detail['analyzed_doi'],
                'DOI –ø–µ—Ä–≤–æ–π —Ü–∏—Ç–∏—Ä—É—é—â–µ–π —Ä–∞–±–æ—Ç—ã': detail['citing_doi'],
                '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': detail['analyzed_date'].strftime('%Y-%m-%d'),
                '–î–∞—Ç–∞ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': detail['first_citation_date'].strftime('%Y-%m-%d'),
                '–î–Ω–µ–π –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': detail['days_to_first_citation']
            })
        
        if first_citation_list:
            first_citation_df = pd.DataFrame(first_citation_list)
            first_citation_df.to_excel(writer, sheet_name='–ü–µ—Ä–≤—ã–µ_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', index=False)

        # –õ–∏—Å—Ç 5: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
        analyzed_stats_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                '–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π', 
                '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫', 
                '–°—Å—ã–ª–∫–∏ —Å DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ —Å DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ —Å DOI',
                '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI',
                '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                '–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º',
                '–°—Ç–∞—Ç—å–∏ —Å >10 –∞–≤—Ç–æ—Ä–∞–º–∏', 
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫',
                '–ú–µ–¥–∏–∞–Ω–∞ —Å—Å—ã–ª–æ–∫', 
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤', 
                '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                '–ú–µ–¥–∏–∞–Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤', 
                '–°—Ç–∞—Ç—å–∏ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã',
                '–°—Ç–∞—Ç—å–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω',
                '–°—Ç–∞—Ç—å–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö',
                '–í—Å–µ–≥–æ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π', 
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π',
                '–°—Ç–∞—Ç—å–∏ —Å ‚â•10 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                '–°—Ç–∞—Ç—å–∏ —Å ‚â•50 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                '–°—Ç–∞—Ç—å–∏ —Å ‚â•100 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                '–°—Ç–∞—Ç—å–∏ —Å ‚â•200 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                analyzed_stats['n_items'],
                analyzed_stats['total_refs'],
                '–°—Å—ã–ª–∫–∏ —Å DOI', analyzed_stats['refs_with_doi'], f"{analyzed_stats['refs_with_doi_pct']:.1f}%",
                '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', analyzed_stats['refs_without_doi'], f"{analyzed_stats['refs_without_doi_pct']:.1f}%",
                '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', analyzed_stats['self_cites'], f"{analyzed_stats['self_cites_pct']:.1f}%",
                analyzed_stats['single_authors'],
                analyzed_stats['multi_authors_gt10'],
                analyzed_stats['ref_min'],
                analyzed_stats['ref_max'],
                f"{analyzed_stats['ref_mean']:.1f}",
                analyzed_stats['ref_median'],
                analyzed_stats['auth_min'],
                analyzed_stats['auth_max'],
                f"{analyzed_stats['auth_mean']:.1f}",
                analyzed_stats['auth_median'],
                analyzed_stats['single_country_articles'], f"{analyzed_stats['single_country_pct']:.1f}%",
                analyzed_stats['multi_country_articles'], f"{analyzed_stats['multi_country_pct']:.1f}%",
                analyzed_stats['no_country_articles'], f"{analyzed_stats['no_country_pct']:.1f}%",
                analyzed_stats['total_affiliations_count'],
                analyzed_stats['unique_affiliations_count'],
                analyzed_stats['unique_countries_count'],
                analyzed_stats['unique_journals_count'],
                analyzed_stats['unique_publishers_count'],
                analyzed_stats['articles_with_10_citations'],
                analyzed_stats['articles_with_50_citations'],
                analyzed_stats['articles_with_100_citations'],
                analyzed_stats['articles_with_200_citations']
            ]
        }
        analyzed_stats_df = pd.DataFrame(analyzed_stats_data)
        analyzed_stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö', index=False)

        # –õ–∏—Å—Ç 6: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π
        citing_stats_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                '–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π', 
                '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫', 
                '–°—Å—ã–ª–∫–∏ —Å DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ —Å DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ —Å DOI',
                '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Å—ã–ª–æ–∫ –±–µ–∑ DOI',
                '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                '–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º',
                '–°—Ç–∞—Ç—å–∏ —Å >10 –∞–≤—Ç–æ—Ä–∞–º–∏', 
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫', 
                '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Å—Å—ã–ª–æ–∫',
                '–ú–µ–¥–∏–∞–Ω–∞ —Å—Å—ã–ª–æ–∫', 
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤', 
                '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –∞–≤—Ç–æ—Ä–æ–≤',
                '–ú–µ–¥–∏–∞–Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤', 
                '–°—Ç–∞—Ç—å–∏ –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã',
                '–°—Ç–∞—Ç—å–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω',
                '–°—Ç–∞—Ç—å–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö', '–ü—Ä–æ—Ü–µ–Ω—Ç —Å—Ç–∞—Ç–µ–π –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—Ä–∞–Ω–∞—Ö',
                '–í—Å–µ–≥–æ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π', 
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤',
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                citing_stats['n_items'],
                citing_stats['total_refs'],
                '–°—Å—ã–ª–∫–∏ —Å DOI', citing_stats['refs_with_doi'], f"{citing_stats['refs_with_doi_pct']:.1f}%",
                '–°—Å—ã–ª–∫–∏ –±–µ–∑ DOI', citing_stats['refs_without_doi'], f"{citing_stats['refs_without_doi_pct']:.1f}%",
                '–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', citing_stats['self_cites'], f"{citing_stats['self_cites_pct']:.1f}%",
                citing_stats['single_authors'],
                citing_stats['multi_authors_gt10'],
                citing_stats['ref_min'],
                citing_stats['ref_max'],
                f"{citing_stats['ref_mean']:.1f}",
                citing_stats['ref_median'],
                citing_stats['auth_min'],
                citing_stats['auth_max'],
                f"{citing_stats['auth_mean']:.1f}",
                citing_stats['auth_median'],
                citing_stats['single_country_articles'], f"{citing_stats['single_country_pct']:.1f}%",
                citing_stats['multi_country_articles'], f"{citing_stats['multi_country_pct']:.1f}%",
                citing_stats['no_country_articles'], f"{citing_stats['no_country_pct']:.1f}%",
                citing_stats['total_affiliations_count'],
                citing_stats['unique_affiliations_count'],
                citing_stats['unique_countries_count'],
                citing_stats['unique_journals_count'],
                citing_stats['unique_publishers_count']
            ]
        }
        citing_stats_df = pd.DataFrame(citing_stats_data)
        citing_stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞_—Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö', index=False)

        # –õ–∏—Å—Ç 7: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        enhanced_stats_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                'H-index', '–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                '–°—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é', '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', '–°—Ç–∞—Ç—å–∏ —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏',
                '–°—Ç–∞—Ç—å–∏ –±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                enhanced_stats['h_index'],
                enhanced_stats['total_citations'],
                f"{enhanced_stats['avg_citations_per_article']:.1f}",
                enhanced_stats['max_citations'],
                enhanced_stats['min_citations'],
                enhanced_stats['articles_with_citations'],
                enhanced_stats['articles_without_citations']
            ]
        }
        enhanced_stats_df = pd.DataFrame(enhanced_stats_data)
        enhanced_stats_df.to_excel(writer, sheet_name='–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)

        # –õ–∏—Å—Ç 8: Impact Factor, CiteScore –∏ –≤—Ä–µ–º—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–û–ë–ù–û–í–õ–ï–ù–ù–´–ô)
        if_days_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                'Impact Factor (—Ç–µ–∫—É—â–∏–π)', 
                'Impact Factor (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                'Impact Factor (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                'Impact Factor (–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                'CiteScore (—Ç–µ–∫—É—â–∏–π)',
                'CiteScore (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                'CiteScore (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                'CiteScore (–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑)',
                '–ß–∏—Å–ª–∏—Ç–µ–ª—å IF (—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)', 
                '–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å IF (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏)', 
                '–ß–∏—Å–ª–∏—Ç–µ–ª—å CiteScore (—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)',
                '–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å CiteScore (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏)',
                '–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π –¥–ª—è IF',
                '–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π –¥–ª—è CiteScore',
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 
                '–°—Ä–µ–¥–Ω–∏–µ –¥–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                '–ú–µ–¥–∏–∞–Ω–∞ –¥–Ω–µ–π –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 
                '–°—Ç–∞—Ç—å–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                '–í—Å–µ–≥–æ –ª–µ—Ç –ø–æ–∫—Ä—ã—Ç–æ –¥–∞–Ω–Ω—ã–º–∏ –æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è—Ö',
                '–û–±–ª–∞—Å—Ç—å –∂—É—Ä–Ω–∞–ª–∞',
                '–ú–Ω–æ–∂–∏—Ç–µ–ª—å (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π)',
                '–ú–Ω–æ–∂–∏—Ç–µ–ª—å (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)',
                '–ú–Ω–æ–∂–∏—Ç–µ–ª—å (–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π)'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                f"{if_days.get('if_value', 0):.4f}",
                f"{if_days.get('if_forecasts', {}).get('conservative', 0):.4f}",
                f"{if_days.get('if_forecasts', {}).get('balanced', 0):.4f}",
                f"{if_days.get('if_forecasts', {}).get('optimistic', 0):.4f}",
                f"{if_days.get('citescore_value', 0):.4f}",
                f"{if_days.get('citescore_forecasts', {}).get('conservative', 0):.4f}",
                f"{if_days.get('citescore_forecasts', {}).get('balanced', 0):.4f}",
                f"{if_days.get('citescore_forecasts', {}).get('optimistic', 0):.4f}",
                if_days.get('c_num', 0),
                if_days.get('p_den', 0),
                if_days.get('cs_c_num', 0),
                if_days.get('cs_p_den', 0),
                f"{if_days.get('publication_years', ['N/A', 'N/A'])[0] if if_days.get('publication_years') else 'N/A'}-{if_days.get('publication_years', ['N/A', 'N/A'])[1] if if_days.get('publication_years') and len(if_days['publication_years']) > 1 else 'N/A'}",
                f"{if_days.get('cs_publication_years', ['N/A', 'N/A'])[0] if if_days.get('cs_publication_years') else 'N/A'}-{if_days.get('cs_publication_years', ['N/A', 'N/A'])[-1] if if_days.get('cs_publication_years') else 'N/A'}",
                if_days.get('days_min', 0),
                if_days.get('days_max', 0),
                f"{if_days.get('days_mean', 0):.1f}",
                if_days.get('days_median', 0),
                if_days.get('articles_with_timing_data', 0),
                if_days.get('total_years_covered', 0),
                if_days.get('journal_field', 'general'),
                f"{if_days.get('multipliers', {}).get('conservative', 1):.2f}",
                f"{if_days.get('multipliers', {}).get('balanced', 1):.2f}",
                f"{if_days.get('multipliers', {}).get('optimistic', 1):.2f}"
            ]
        }
        if_days_df = pd.DataFrame(if_days_data)
        if_days_df.to_excel(writer, sheet_name='Impact_Factor_CiteScore_–í—Ä–µ–º—è', index=False)

        # –õ–∏—Å—Ç 9: –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–æ–¥–∞–º
        yearly_citations_data = []
        for yearly_stat in if_days.get('yearly_citations', []):
            yearly_citations_data.append({
                '–ì–æ–¥': yearly_stat.get('year', 0),
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π': yearly_stat.get('citations_count', 0)
            })
        
        if yearly_citations_data:
            yearly_citations_df = pd.DataFrame(yearly_citations_data)
            yearly_citations_df.to_excel(writer, sheet_name='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è_–ø–æ_–≥–æ–¥–∞–º', index=False)

        # –õ–∏—Å—Ç 10: –ö—Ä–∏–≤—ã–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        accumulation_data = []
        for pub_year, curve_data in if_days.get('accumulation_curves', {}).items():
            for data_point in curve_data:
                accumulation_data.append({
                    '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_year,
                    '–õ–µ—Ç –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': data_point.get('years_since_publication', 0),
                    '–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': data_point.get('cumulative_citations', 0)
                })
        
        if accumulation_data:
            accumulation_df = pd.DataFrame(accumulation_data)
            accumulation_df.to_excel(writer, sheet_name='–ö—Ä–∏–≤—ã–µ_–Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', index=False)

        # –õ–∏—Å—Ç 11: –°–µ—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        citation_network_data = []
        for year, citing_years in enhanced_stats.get('citation_network', {}).items():
            year_counts = Counter(citing_years)
            for citing_year, count in year_counts.items():
                citation_network_data.append({
                    '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': year,
                    '–ì–æ–¥ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è': citing_year,
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π': count
                })
        
        if citation_network_data:
            citation_network_df = pd.DataFrame(citation_network_data)
            citation_network_df.to_excel(writer, sheet_name='–°–µ—Ç—å_—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π', index=False)

        # –õ–∏—Å—Ç 12: –í—Å–µ –∞–≤—Ç–æ—Ä—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
        all_authors_data = {
            '–ê–≤—Ç–æ—Ä': [author[0] for author in analyzed_stats['all_authors']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [author[1] for author in analyzed_stats['all_authors']]
        }
        all_authors_df = pd.DataFrame(all_authors_data)
        all_authors_df.to_excel(writer, sheet_name='–í—Å–µ_–∞–≤—Ç–æ—Ä—ã_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

        # –õ–∏—Å—Ç 13: –í—Å–µ –∞–≤—Ç–æ—Ä—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
        all_citing_authors_data = {
            '–ê–≤—Ç–æ—Ä': [author[0] for author in citing_stats['all_authors']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [author[1] for author in citing_stats['all_authors']]
        }
        all_citing_authors_df = pd.DataFrame(all_citing_authors_data)
        all_citing_authors_df.to_excel(writer, sheet_name='–í—Å–µ_–∞–≤—Ç–æ—Ä—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

        # –õ–∏—Å—Ç 14: –í—Å–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
        all_affiliations_data = {
            '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è': [aff[0] for aff in analyzed_stats['all_affiliations']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [aff[1] for aff in analyzed_stats['all_affiliations']]
        }
        all_affiliations_df = pd.DataFrame(all_affiliations_data)
        all_affiliations_df.to_excel(writer, sheet_name='–í—Å–µ_–∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

        # –õ–∏—Å—Ç 15: –í—Å–µ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
        all_citing_affiliations_data = {
            '–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è': [aff[0] for aff in citing_stats['all_affiliations']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [aff[1] for aff in citing_stats['all_affiliations']]
        }
        all_citing_affiliations_df = pd.DataFrame(all_citing_affiliations_data)
        all_citing_affiliations_df.to_excel(writer, sheet_name='–í—Å–µ_–∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–∏_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

        # –õ–∏—Å—Ç 16: –í—Å–µ —Å—Ç—Ä–∞–Ω—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö
        all_countries_data = {
            '–°—Ç—Ä–∞–Ω–∞': [country[0] for country in analyzed_stats['all_countries']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [country[1] for country in analyzed_stats['all_countries']]
        }
        all_countries_df = pd.DataFrame(all_countries_data)
        all_countries_df.to_excel(writer, sheet_name='–í—Å–µ_—Å—Ç—Ä–∞–Ω—ã_–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ', index=False)

        # –õ–∏—Å—Ç 17: –í—Å–µ —Å—Ç—Ä–∞–Ω—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö
        all_citing_countries_data = {
            '–°—Ç—Ä–∞–Ω–∞': [country[0] for country in citing_stats['all_countries']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π': [country[1] for country in citing_stats['all_countries']]
        }
        all_citing_countries_df = pd.DataFrame(all_citing_countries_data)
        all_citing_countries_df.to_excel(writer, sheet_name='–í—Å–µ_—Å—Ç—Ä–∞–Ω—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

        # –õ–∏—Å—Ç 18: –í—Å–µ –∂—É—Ä–Ω–∞–ª—ã —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö (–ò–ó–ú–ï–ù–ï–ù–û - —Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ –∂—É—Ä–Ω–∞–ª—ã)
        all_citing_journals_data = {
            '–ñ—É—Ä–Ω–∞–ª': [journal[0] for journal in citing_stats['all_journals']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [journal[1] for journal in citing_stats['all_journals']]
        }
        all_citing_journals_df = pd.DataFrame(all_citing_journals_data)
        all_citing_journals_df.to_excel(writer, sheet_name='–í—Å–µ_–∂—É—Ä–Ω–∞–ª—ã_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

        # –õ–∏—Å—Ç 19: –í—Å–µ –∏–∑–¥–∞—Ç–µ–ª–∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö (–ò–ó–ú–ï–ù–ï–ù–û - —Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ –∏–∑–¥–∞—Ç–µ–ª–∏)
        all_citing_publishers_data = {
            '–ò–∑–¥–∞—Ç–µ–ª—å': [publisher[0] for publisher in citing_stats['all_publishers']],
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π': [publisher[1] for publisher in citing_stats['all_publishers']]
        }
        all_citing_publishers_df = pd.DataFrame(all_citing_publishers_data)
        all_citing_publishers_df.to_excel(writer, sheet_name='–í—Å–µ_–∏–∑–¥–∞—Ç–µ–ª–∏_—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ', index=False)

    return filename

# === 19. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø) ===
def create_visualizations(analyzed_stats, citing_stats, enhanced_stats, if_days, overlap_details):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞"""
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üìà –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏", 
        "üë• –ê–≤—Ç–æ—Ä—ã –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏", 
        "üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—è", 
        "üìä –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        "üîÄ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è",
        "‚è±Ô∏è –í—Ä–µ–º—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
        "üéØ IF & CiteScore"
    ])
    
    with tab1:
        st.subheader("üìà –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∂—É—Ä–Ω–∞–ª–∞")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Impact Factor", 
                f"{if_days.get('if_value', 0):.4f}",
                help=f"–†–∞—Å—á–µ—Ç –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π {if_days.get('publication_years', [0, 0])[0]}-{if_days.get('publication_years', [0, 0])[1]}"
            )
        with col2:
            st.metric(
                "CiteScore", 
                f"{if_days.get('citescore_value', 0):.4f}",
                help=f"–†–∞—Å—á–µ—Ç –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π {if_days.get('cs_publication_years', [0, 0])[0]}-{if_days.get('cs_publication_years', [0, 0])[-1]}"
            )
        with col3:
            st.metric("H-index", enhanced_stats.get('h_index', 0))
        with col4:
            st.metric("–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π", analyzed_stats.get('n_items', 0))
        
        col5, col6, col7, col8 = st.columns(4)
        
        with col5:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π", f"{enhanced_stats.get('avg_citations_per_article', 0):.1f}")
        with col6:
            st.metric("–°—Ç–∞—Ç—å–∏ —Å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏", enhanced_stats.get('articles_with_citations', 0))
        with col7:
            st.metric("–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{analyzed_stats.get('self_cites_pct', 0):.1f}%")
        with col8:
            st.metric("–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏", f"{analyzed_stats.get('multi_country_pct', 0):.1f}%")
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ –≥–æ–¥–∞–º
        if if_days.get('yearly_citations'):
            years = [item.get('year', 0) for item in if_days['yearly_citations']]
            citations = [item.get('citations_count', 0) for item in if_days['yearly_citations']]
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=years, 
                y=citations, 
                name='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                marker_color='lightblue'
            ))
            fig.update_layout(
                title='–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –≥–æ–¥–∞–º',
                xaxis_title='–ì–æ–¥',
                yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("üë• –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä–æ–≤ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –¢–æ–ø –∞–≤—Ç–æ—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
            if analyzed_stats.get('all_authors'):
                top_authors = analyzed_stats['all_authors'][:15]
                authors_df = pd.DataFrame(top_authors, columns=['–ê–≤—Ç–æ—Ä', '–°—Ç–∞—Ç–µ–π'])
                fig = px.bar(
                    authors_df, 
                    x='–°—Ç–∞—Ç–µ–π', 
                    y='–ê–≤—Ç–æ—Ä', 
                    orientation='h',
                    title='–¢–æ–ø-15 –∞–≤—Ç–æ—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ—Ä–æ–≤
            author_counts_data = {
                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': ['1 –∞–≤—Ç–æ—Ä', '2-5 –∞–≤—Ç–æ—Ä–æ–≤', '6-10 –∞–≤—Ç–æ—Ä–æ–≤', '>10 –∞–≤—Ç–æ—Ä–æ–≤'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats.get('single_authors', 0),
                    analyzed_stats.get('n_items', 0) - analyzed_stats.get('single_authors', 0) - analyzed_stats.get('multi_authors_gt10', 0),
                    analyzed_stats.get('multi_authors_gt10', 0),
                    0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é
                ]
            }
            fig = px.pie(
                author_counts_data, 
                values='–°—Ç–∞—Ç—å–∏', 
                names='–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–≤—Ç–æ—Ä–æ–≤'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # –¢–æ–ø –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π
        if analyzed_stats.get('all_affiliations'):
            top_affiliations = analyzed_stats['all_affiliations'][:10]
            aff_df = pd.DataFrame(top_affiliations, columns=['–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è', '–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'])
            fig = px.bar(
                aff_df, 
                x='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π', 
                y='–ê—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è', 
                orientation='h',
                title='–¢–æ–ø-10 –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π',
                color='–£–ø–æ–º–∏–Ω–∞–Ω–∏–π'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º
            if analyzed_stats.get('all_countries'):
                countries_df = pd.DataFrame(analyzed_stats['all_countries'], columns=['–°—Ç—Ä–∞–Ω–∞', '–°—Ç–∞—Ç–µ–π'])
                fig = px.pie(
                    countries_df, 
                    values='–°—Ç–∞—Ç–µ–π', 
                    names='–°—Ç—Ä–∞–Ω–∞',
                    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –ø–æ —Å—Ç—Ä–∞–Ω–∞–º'
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è
            collaboration_data = {
                '–¢–∏–ø': ['–û–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∞', '–ù–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats.get('single_country_articles', 0),
                    analyzed_stats.get('multi_country_articles', 0),
                    analyzed_stats.get('no_country_articles', 0)
                ]
            }
            fig = px.bar(
                collaboration_data, 
                x='–¢–∏–ø', 
                y='–°—Ç–∞—Ç—å–∏',
                title='–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è',
                color='–¢–∏–ø'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –ø–æ—Ä–æ–≥–∞–º
            citation_thresholds = {
                '–ü–æ—Ä–æ–≥': ['‚â•10', '‚â•50', '‚â•100', '‚â•200'],
                '–°—Ç–∞—Ç—å–∏': [
                    analyzed_stats.get('articles_with_10_citations', 0),
                    analyzed_stats.get('articles_with_50_citations', 0),
                    analyzed_stats.get('articles_with_100_citations', 0),
                    analyzed_stats.get('articles_with_200_citations', 0)
                ]
            }
            fig = px.bar(
                citation_thresholds, 
                x='–ü–æ—Ä–æ–≥', 
                y='–°—Ç–∞—Ç—å–∏',
                title='–°—Ç–∞—Ç—å–∏ –ø–æ –ø–æ—Ä–æ–≥–∞–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                color='–ü–æ—Ä–æ–≥'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # –°—Ç–∞—Ç—å–∏ —Å/–±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            citation_status = {
                '–°—Ç–∞—Ç—É—Å': ['–° —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏', '–ë–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'],
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [
                    enhanced_stats.get('articles_with_citations', 0),
                    enhanced_stats.get('articles_without_citations', 0)
                ]
            }
            fig = px.pie(
                citation_status, 
                values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 
                names='–°—Ç–∞—Ç—É—Å',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –ø–æ –Ω–∞–ª–∏—á–∏—é —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab5:
        st.subheader("üîÄ –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏")
        
        if overlap_details:
            # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è–º
            total_overlaps = len(overlap_details)
            articles_with_overlaps = len(set([o.get('analyzed_doi', '') for o in overlap_details]))
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π", total_overlaps)
            with col2:
                st.metric("–°—Ç–∞—Ç–µ–π —Å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è–º–∏", articles_with_overlaps)
            with col3:
                avg_overlaps = total_overlaps / articles_with_overlaps if articles_with_overlaps > 0 else 0
                st.metric("–°—Ä–µ–¥–Ω–µ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é", f"{avg_overlaps:.1f}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
            overlap_counts = [o.get('common_authors_count', 0) + o.get('common_affiliations_count', 0) for o in overlap_details]
            if overlap_counts:
                fig = px.histogram(
                    x=overlap_counts,
                    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É',
                    labels={'x': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π', 'y': '–ß–∞—Å—Ç–æ—Ç–∞'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª—è–º–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
            st.subheader("–î–µ—Ç–∞–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π")
            overlap_df = pd.DataFrame(overlap_details)
            st.dataframe(overlap_df[['analyzed_doi', 'citing_doi', 'common_authors_count', 'common_affiliations_count']])
        else:
            st.info("‚ùå –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º–∏ –∏ —Ü–∏—Ç–∏—Ä—É—é—â–∏–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    with tab6:
        st.subheader("‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–ú–∏–Ω. –¥–Ω–µ–π –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", if_days.get('days_min', 0))
        with col2:
            st.metric("–ú–∞–∫—Å. –¥–Ω–µ–π –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", if_days.get('days_max', 0))
        with col3:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –¥–Ω–µ–π", f"{if_days.get('days_mean', 0):.1f}")
        with col4:
            st.metric("–ú–µ–¥–∏–∞–Ω–∞ –¥–Ω–µ–π", if_days.get('days_median', 0))
        
        # –î–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        if if_days.get('first_citation_details'):
            st.subheader("–î–µ—Ç–∞–ª–∏ –ø–µ—Ä–≤—ã—Ö —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
            first_citation_df = pd.DataFrame(if_days['first_citation_details'])
            st.dataframe(first_citation_df)
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            days_data = [d.get('days_to_first_citation', 0) for d in if_days['first_citation_details']]
            fig = px.histogram(
                x=days_data,
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–Ω–∏)',
                labels={'x': '–î–Ω–∏ –¥–æ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab7:
        st.subheader("üéØ Impact Factor –∏ CiteScore - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### Impact Factor")
            st.metric("–¢–µ–∫—É—â–∏–π IF", f"{if_days.get('if_value', 0):.4f}")
            st.metric("–ß–∏—Å–ª–∏—Ç–µ–ª—å (—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)", if_days.get('c_num', 0))
            st.metric("–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏)", if_days.get('p_den', 0))
            st.metric("–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π", f"{if_days.get('publication_years', ['N/A', 'N/A'])[0] if if_days.get('publication_years') else 'N/A'}-{if_days.get('publication_years', ['N/A', 'N/A'])[1] if if_days.get('publication_years') and len(if_days['publication_years']) > 1 else 'N/A'}")
            
            st.markdown("##### –ü—Ä–æ–≥–Ω–æ–∑—ã IF")
            forecast_data = {
                '–¢–∏–ø –ø—Ä–æ–≥–Ω–æ–∑–∞': ['–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π', '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π', '–û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π'],
                '–ó–Ω–∞—á–µ–Ω–∏–µ IF': [
                    if_days.get('if_forecasts', {}).get('conservative', 0),
                    if_days.get('if_forecasts', {}).get('balanced', 0),
                    if_days.get('if_forecasts', {}).get('optimistic', 0)
                ],
                '–ú–Ω–æ–∂–∏—Ç–µ–ª—å': [
                    if_days.get('multipliers', {}).get('conservative', 1),
                    if_days.get('multipliers', {}).get('balanced', 1),
                    if_days.get('multipliers', {}).get('optimistic', 1)
                ]
            }
            forecast_df = pd.DataFrame(forecast_data)
            st.dataframe(forecast_df)
        
        with col2:
            st.markdown("##### CiteScore")
            st.metric("–¢–µ–∫—É—â–∏–π CiteScore", f"{if_days.get('citescore_value', 0):.4f}")
            st.metric("–ß–∏—Å–ª–∏—Ç–µ–ª—å (—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)", if_days.get('cs_c_num', 0))
            st.metric("–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏)", if_days.get('cs_p_den', 0))
            st.metric("–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π CiteScore", f"{if_days.get('cs_publication_years', ['N/A', 'N/A'])[0] if if_days.get('cs_publication_years') else 'N/A'}-{if_days.get('cs_publication_years', ['N/A', 'N/A'])[-1] if if_days.get('cs_publication_years') else 'N/A'}")
            
            st.markdown("##### –ü—Ä–æ–≥–Ω–æ–∑—ã CiteScore")
            cs_forecast_data = {
                '–¢–∏–ø –ø—Ä–æ–≥–Ω–æ–∑–∞': ['–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π', '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π', '–û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π'],
                '–ó–Ω–∞—á–µ–Ω–∏–µ CiteScore': [
                    if_days.get('citescore_forecasts', {}).get('conservative', 0),
                    if_days.get('citescore_forecasts', {}).get('balanced', 0),
                    if_days.get('citescore_forecasts', {}).get('optimistic', 0)
                ],
                '–ú–Ω–æ–∂–∏—Ç–µ–ª—å': [
                    if_days.get('multipliers', {}).get('conservative', 1),
                    if_days.get('multipliers', {}).get('balanced', 1),
                    if_days.get('multipliers', {}).get('optimistic', 1)
                ]
            }
            cs_forecast_df = pd.DataFrame(cs_forecast_data)
            st.dataframe(cs_forecast_df)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        if if_days.get('citation_distribution'):
            months = list(range(1, 13))
            coefficients = [if_days['citation_distribution'].get(month, 1) for month in months]
            month_names = ['–Ø–Ω–≤', '–§–µ–≤', '–ú–∞—Ä', '–ê–ø—Ä', '–ú–∞–π', '–ò—é–Ω', '–ò—é–ª', '–ê–≤–≥', '–°–µ–Ω', '–û–∫—Ç', '–ù–æ—è', '–î–µ–∫']
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=month_names,
                y=coefficients,
                name='–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π',
                marker_color='orange'
            ))
            fig.update_layout(
                title='–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –ø–æ –º–µ—Å—è—Ü–∞–º',
                xaxis_title='–ú–µ—Å—è—Ü',
                yaxis_title='–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç',
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)

# === 20. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ (–û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø) ===
def analyze_journal(issn, period_str):
    global delayer
    delayer = AdaptiveDelayer()
    
    state = get_analysis_state()
    state.analysis_complete = False
    
    # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    overall_progress = st.progress(0)
    overall_status = st.empty()
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞
    overall_status.text("üìÖ –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–∏–æ–¥–∞...")
    years = parse_period(period_str)
    if not years:
        return
    from_date = f"{min(years)}-01-01"
    until_date = f"{max(years)}-12-31"
    overall_progress.progress(0.1)
    
    # –ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞
    overall_status.text("üìñ –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∂—É—Ä–Ω–∞–ª–∞...")
    journal_name = get_journal_name(issn)
    st.success(f"üìñ –ñ—É—Ä–Ω–∞–ª: **{journal_name}** (ISSN: {issn})")
    overall_progress.progress(0.2)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π
    overall_status.text("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref...")
    items = fetch_articles_by_issn_period(issn, from_date, until_date)
    if not items:
        st.error("‚ùå –°—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    n_analyzed = len(items)
    st.success(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π: **{n_analyzed}**")
    overall_progress.progress(0.3)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    overall_status.text("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    validated_items = validate_and_clean_data(items)
    journal_prefix = get_doi_prefix(validated_items[0].get('DOI', '')) if validated_items else ''
    overall_progress.progress(0.4)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π
    overall_status.text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π...")
    
    analyzed_metadata = []
    dois = [item.get('DOI') for item in validated_items if item.get('DOI')]
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    meta_progress = st.progress(0)
    meta_status = st.empty()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤
    args_list = [(doi, state) for doi in dois]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(get_unified_metadata, args): args for args in args_list}
        
        for i, future in enumerate(as_completed(futures)):
            args = futures[future]
            doi = args[0]
            try:
                result = future.result()
                analyzed_metadata.append({
                    'doi': doi,
                    'crossref': result['crossref'],
                    'openalex': result['openalex']
                })
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOI {doi}: {e}")
            
            progress = (i + 1) / len(dois)
            meta_progress.progress(progress)
            meta_status.text(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {i + 1}/{len(dois)}")
    
    meta_progress.empty()
    meta_status.empty()
    overall_progress.progress(0.6)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç
    overall_status.text("üîó –°–±–æ—Ä —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç...")
    
    all_citing_metadata = []
    analyzed_dois = [am['doi'] for am in analyzed_metadata if am.get('doi')]
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è —Å–±–æ—Ä–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
    citing_progress = st.progress(0)
    citing_status = st.empty()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤
    citing_args_list = [(doi, state) for doi in analyzed_dois]
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(get_citing_dois_and_metadata, args): args for args in citing_args_list}
        
        for i, future in enumerate(as_completed(futures)):
            args = futures[future]
            doi = args[0]
            try:
                citings = future.result()
                all_citing_metadata.extend(citings)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –¥–ª—è {doi}: {e}")
            
            progress = (i + 1) / len(analyzed_dois)
            citing_progress.progress(progress)
            citing_status.text(f"–°–±–æ—Ä —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π: {i + 1}/{len(analyzed_dois)}")
    
    citing_progress.empty()
    citing_status.empty()
    
    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã
    unique_citing_dois = set(c['doi'] for c in all_citing_metadata if c.get('doi'))
    n_citing = len(unique_citing_dois)
    st.success(f"üìÑ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç: **{n_citing}**")
    overall_progress.progress(0.8)
    
    # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    overall_status.text("üìä –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    
    analyzed_stats = extract_stats_from_metadata(analyzed_metadata, journal_prefix=journal_prefix)
    citing_stats = extract_stats_from_metadata(all_citing_metadata, is_analyzed=False)
    enhanced_stats = enhanced_stats_calculation(analyzed_metadata, all_citing_metadata, state)
    
    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
    overlap_details = analyze_overlaps(analyzed_metadata, all_citing_metadata, state)
    
    current_date = datetime.now()
    if_days = calculate_if_and_days(analyzed_metadata, all_citing_metadata, current_date, state, issn, journal_name)
    
    overall_progress.progress(0.9)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    overall_status.text("üíæ –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'journal_analysis_{issn}_{timestamp}.xlsx'
    
    # –°–æ–∑–¥–∞–µ–º Excel —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏
    excel_buffer = io.BytesIO()
    create_enhanced_excel_report(analyzed_metadata, all_citing_metadata, analyzed_stats, citing_stats, enhanced_stats, if_days, overlap_details, excel_buffer)
    
    excel_buffer.seek(0)
    state.excel_buffer = excel_buffer
    
    overall_progress.progress(1.0)
    overall_status.text("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    state.analysis_results = {
        'analyzed_stats': analyzed_stats,
        'citing_stats': citing_stats,
        'enhanced_stats': enhanced_stats,
        'if_days': if_days,
        'overlap_details': overlap_details,
        'journal_name': journal_name,
        'issn': issn,
        'period': period_str,
        'n_analyzed': n_analyzed,
        'n_citing': n_citing
    }
    
    state.analysis_complete = True
    
    time.sleep(1)
    overall_progress.empty()
    overall_status.empty()

# === 21. –ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===
def main():
    initialize_analysis_state()
    state = get_analysis_state()
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üî¨ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—É—á–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤")
    st.markdown("---")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –≤–≤–æ–¥–æ–º –¥–∞–Ω–Ω—ã—Ö
    with st.sidebar:
        st.header("üìù –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        issn = st.text_input(
            "ISSN –∂—É—Ä–Ω–∞–ª–∞:",
            value="2411-1414",
            help="–í–≤–µ–¥–∏—Ç–µ ISSN –∂—É—Ä–Ω–∞–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        )
        
        period = st.text_input(
            "–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:",
            value="2022-2024",
            help="–ü—Ä–∏–º–µ—Ä—ã: 2022, 2022-2024, 2022,2024"
        )
        
        st.markdown("---")
        st.header("üí° –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        st.info("""
        **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞:**
        - üìä Impact Factor –∏ CiteScore
        - üë• –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä–æ–≤ –∏ –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π
        - üåç –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        - üîó –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–∞–º–∏
        - ‚è±Ô∏è –í—Ä–µ–º—è –¥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        - üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        - üéØ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        """)
        
        st.warning("""
        **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** 
        - –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç
        - –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ ISSN
        - –î–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è
        """)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞")
        
        if st.button("–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", use_container_width=True):
            if not issn:
                st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ ISSN –∂—É—Ä–Ω–∞–ª–∞")
                return
                
            if not period:
                st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞")
                return
                
            with st.spinner("–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞..."):
                analyze_journal(issn, period)
    
    with col2:
        st.subheader("üì§ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        
        if state.analysis_complete and state.excel_buffer is not None:
            results = state.analysis_results
            
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å Excel –æ—Ç—á–µ—Ç",
                data=state.excel_buffer,
                file_name=f"journal_analysis_{results['issn']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if state.analysis_complete:
        st.markdown("---")
        st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        results = state.analysis_results
        
        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–ñ—É—Ä–Ω–∞–ª", results['journal_name'])
        with col2:
            st.metric("ISSN", results['issn'])
        with col3:
            st.metric("–ü–µ—Ä–∏–æ–¥", results['period'])
        with col4:
            st.metric("–°—Ç–∞—Ç–µ–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", results['n_analyzed'])
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        create_visualizations(
            results['analyzed_stats'],
            results['citing_stats'], 
            results['enhanced_stats'],
            results['if_days'],
            results['overlap_details']
        )
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        st.markdown("---")
        st.header("üìà –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        tab1, tab2, tab3, tab4 = st.tabs(["–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ —Å—Ç–∞—Ç—å–∏", "–¶–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã", "–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "–ú–µ—Ç—Ä–∏–∫–∏ –∂—É—Ä–Ω–∞–ª–∞"])
        
        with tab1:
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å—Ç–∞—Ç–µ–π")
            stats = results['analyzed_stats']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π", stats['n_items'])
                st.metric("–°—Ç–∞—Ç—å–∏ —Å –æ–¥–Ω–∏–º –∞–≤—Ç–æ—Ä–æ–º", stats['single_authors'])
                st.metric("–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏", f"{stats['multi_country_pct']:.1f}%")
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π", stats['unique_affiliations_count'])
                
            with col2:
                st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫", stats['total_refs'])
                st.metric("–°–∞–º–æ—Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{stats['self_cites_pct']:.1f}%")
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω", stats['unique_countries_count'])
                st.metric("–°—Ç–∞—Ç—å–∏ —Å ‚â•10 —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏", stats['articles_with_10_citations'])
        
        with tab2:
            st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Ä–∞–±–æ—Ç")
            stats = results['citing_stats']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π", stats['n_items'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤", stats['unique_journals_count'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–¥–∞—Ç–µ–ª–µ–π", stats['unique_publishers_count'])
                
            with col2:
                st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫", stats['total_refs'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏–π", stats['unique_affiliations_count'])
                st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω", stats['unique_countries_count'])
        
        with tab3:
            st.subheader("–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ –∞–≤—Ç–æ—Ä–æ–≤ –Ω–∞ —Å—Ç–∞—Ç—å—é (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ)", 
                    f"{results['analyzed_stats']['auth_mean']:.1f}"
                )
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é (–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–µ)", 
                    f"{results['analyzed_stats']['ref_mean']:.1f}"
                )
                
            with col2:
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ –∞–≤—Ç–æ—Ä–æ–≤ –Ω–∞ —Å—Ç–∞—Ç—å—é (—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ)", 
                    f"{results['citing_stats']['auth_mean']:.1f}"
                )
                st.metric(
                    "–°—Ä–µ–¥–Ω–µ–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é (—Ü–∏—Ç–∏—Ä—É—é—â–∏–µ)", 
                    f"{results['citing_stats']['ref_mean']:.1f}"
                )
        
        with tab4:
            st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∂—É—Ä–Ω–∞–ª–∞")
            if_days = results['if_days']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Impact Factor", f"{if_days.get('if_value', 0):.4f}")
                st.metric("–ß–∏—Å–ª–∏—Ç–µ–ª—å IF", if_days.get('c_num', 0))
                st.metric("–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å IF", if_days.get('p_den', 0))
                st.metric("–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π IF", f"{if_days.get('publication_years', [0, 0])[0]}-{if_days.get('publication_years', [0, 0])[1]}")
                
            with col2:
                st.metric("CiteScore", f"{if_days.get('citescore_value', 0):.4f}")
                st.metric("–ß–∏—Å–ª–∏—Ç–µ–ª—å CiteScore", if_days.get('cs_c_num', 0))
                st.metric("–ó–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å CiteScore", if_days.get('cs_p_den', 0))
                st.metric("–ì–æ–¥—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–π CiteScore", f"{if_days.get('cs_publication_years', [0, 0])[0]}-{if_days.get('cs_publication_years', [0, 0])[-1]}")

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    main()


